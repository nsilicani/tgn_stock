{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVkYgs2R1l83"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9asHWEx2DSN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',  force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvFgRO1o1y2K"
   },
   "outputs": [],
   "source": [
    "! pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl-4K0Sn1l84"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJR4BQvl2P-U"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class GraphData:\n",
    "  def __init__(self, sources: np.ndarray,\n",
    "        destinations: np.ndarray, timestamps: np.ndarray, edge_idxs: np.ndarray, source_labels: np.ndarray, dest_labels: np.ndarray, limit: Optional[int] = None):\n",
    "    self.sources = sources if limit is None else sources[:limit]\n",
    "    self.destinations = destinations if limit is None else destinations[:limit]\n",
    "    self.timestamps = timestamps if limit is None else timestamps[:limit]\n",
    "    self.edge_idxs = edge_idxs if limit is None else edge_idxs[:limit]\n",
    "    self.source_labels = source_labels if limit is None else source_labels[:limit]\n",
    "    self.dest_labels = dest_labels if limit is None else dest_labels[:limit]\n",
    "    self.n_interactions = len(self.sources)\n",
    "    self.unique_nodes = set(self.sources) | set(self.destinations)\n",
    "    self.n_unique_nodes = len(self.unique_nodes)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"\"\"GraphData\n",
    "    sources =  {self.sources.shape},\n",
    "    destinations =  {self.destinations.shape},\n",
    "    timestamps =  {self.timestamps.shape},\n",
    "    edge_idxs =  {self.edge_idxs.shape},\n",
    "    source_labels =  {self.source_labels.shape},\n",
    "    dest_labels =  {self.dest_labels.shape},\n",
    "    n_interactions =  {self.n_interactions},\n",
    "    n_unique_nodes =  {self.n_unique_nodes}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class NeighborFinder:\n",
    "  def __init__(self, adj_list, uniform=False, seed=None):\n",
    "    self.node_to_neighbors = []\n",
    "    self.node_to_edge_idxs = []\n",
    "    self.node_to_edge_timestamps = []\n",
    "\n",
    "    for neighbors in adj_list:\n",
    "      # Neighbors is a list of tuples (neighbor, edge_idx, timestamp)\n",
    "      # We sort the list based on timestamp\n",
    "      sorted_neighhbors = sorted(neighbors, key=lambda x: x[2])\n",
    "      self.node_to_neighbors.append(np.array([x[0] for x in sorted_neighhbors]))\n",
    "      self.node_to_edge_idxs.append(np.array([x[1] for x in sorted_neighhbors]))\n",
    "      self.node_to_edge_timestamps.append(np.array([x[2] for x in sorted_neighhbors]))\n",
    "\n",
    "    self.uniform = uniform\n",
    "\n",
    "    if seed is not None:\n",
    "      self.seed = seed\n",
    "      self.random_state = np.random.RandomState(self.seed)\n",
    "\n",
    "  def find_before(self, src_idx, cut_time):\n",
    "    \"\"\"\n",
    "    Extracts all the interactions happening before cut_time for user src_idx in the overall interaction graph. The returned interactions are sorted by time.\n",
    "\n",
    "    Returns 3 lists: neighbors, edge_idxs, timestamps\n",
    "\n",
    "    \"\"\"\n",
    "    i = np.searchsorted(self.node_to_edge_timestamps[src_idx], cut_time)\n",
    "\n",
    "    return self.node_to_neighbors[src_idx][:i], self.node_to_edge_idxs[src_idx][:i], self.node_to_edge_timestamps[src_idx][:i]\n",
    "\n",
    "  def get_temporal_neighbor(self, source_nodes, timestamps, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Given a list of users ids and relative cut times, extracts a sampled temporal neighborhood of each user in the list.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    src_idx_l: List[int]\n",
    "    cut_time_l: List[float],\n",
    "    num_neighbors: int\n",
    "    \"\"\"\n",
    "    assert (len(source_nodes) == len(timestamps))\n",
    "\n",
    "    tmp_n_neighbors = n_neighbors if n_neighbors > 0 else 1\n",
    "    # NB! All interactions described in these matrices are sorted in each row by time\n",
    "    neighbors = np.zeros((len(source_nodes), tmp_n_neighbors)).astype(\n",
    "      np.int32)  # each entry in position (i,j) represent the id of the item targeted by user src_idx_l[i] with an interaction happening before cut_time_l[i]\n",
    "    edge_times = np.zeros((len(source_nodes), tmp_n_neighbors)).astype(\n",
    "      np.float32)  # each entry in position (i,j) represent the timestamp of an interaction between user src_idx_l[i] and item neighbors[i,j] happening before cut_time_l[i]\n",
    "    edge_idxs = np.zeros((len(source_nodes), tmp_n_neighbors)).astype(\n",
    "      np.int32)  # each entry in position (i,j) represent the interaction index of an interaction between user src_idx_l[i] and item neighbors[i,j] happening before cut_time_l[i]\n",
    "\n",
    "\n",
    "    # We initialize neighbors with the node itself\n",
    "    for n in range(len(source_nodes)):\n",
    "      for n_nei in range(tmp_n_neighbors):\n",
    "        neighbors[n, n_nei] = source_nodes[n]\n",
    "        edge_times[n, n_nei] = timestamps[n]\n",
    "        edge_idxs[n, n_nei] = -1\n",
    "\n",
    "    for i, (source_node, timestamp) in enumerate(zip(source_nodes, timestamps)):\n",
    "      source_neighbors, source_edge_idxs, source_edge_times = self.find_before(source_node,\n",
    "                                                   timestamp)  # extracts all neighbors, interactions indexes and timestamps of all interactions of user source_node happening before cut_time\n",
    "\n",
    "      if len(source_neighbors) > 0 and n_neighbors > 0:\n",
    "        if self.uniform:  # if we are applying uniform sampling, shuffles the data above before sampling\n",
    "          sampled_idx = np.random.randint(0, len(source_neighbors), n_neighbors)\n",
    "\n",
    "          neighbors[i, :] = source_neighbors[sampled_idx]\n",
    "          edge_times[i, :] = source_edge_times[sampled_idx]\n",
    "          edge_idxs[i, :] = source_edge_idxs[sampled_idx]\n",
    "\n",
    "          # re-sort based on time\n",
    "          pos = edge_times[i, :].argsort()\n",
    "          neighbors[i, :] = neighbors[i, :][pos]\n",
    "          edge_times[i, :] = edge_times[i, :][pos]\n",
    "          edge_idxs[i, :] = edge_idxs[i, :][pos]\n",
    "        else:\n",
    "          # Take most recent interactions\n",
    "          source_edge_times = source_edge_times[-n_neighbors:]\n",
    "          source_neighbors = source_neighbors[-n_neighbors:]\n",
    "          source_edge_idxs = source_edge_idxs[-n_neighbors:]\n",
    "\n",
    "          assert (len(source_neighbors) <= n_neighbors)\n",
    "          assert (len(source_edge_times) <= n_neighbors)\n",
    "          assert (len(source_edge_idxs) <= n_neighbors)\n",
    "\n",
    "          neighbors[i, n_neighbors - len(source_neighbors):] = source_neighbors\n",
    "          edge_times[i, n_neighbors - len(source_edge_times):] = source_edge_times\n",
    "          edge_idxs[i, n_neighbors - len(source_edge_idxs):] = source_edge_idxs\n",
    "\n",
    "    return neighbors, edge_idxs, edge_times\n",
    "\n",
    "\n",
    "def load_data(data_path: Path, features_path: Path, limit: Optional[int], randomize_features: bool = False, train_size: float = 0.7, test_size: float = 0.25, normalize_features: bool = False) -> GraphData:\n",
    "    df_graph = pd.read_parquet(data_path)\n",
    "    edge_features = df_graph[\"wt\"].values\n",
    "    node_features = np.load(features_path)\n",
    "    if randomize_features:\n",
    "        node_features = np.random.rand(node_features.shape[0], node_features.shape[1])\n",
    "\n",
    "    val_time, test_time = list(np.quantile(df_graph.ts, [train_size, 1-test_size]))\n",
    "\n",
    "    sources = df_graph[\"u\"].values\n",
    "    destinations = df_graph[\"v\"].values\n",
    "    edge_idxs = df_graph[\"idx\"].values\n",
    "    source_labels = df_graph[\"u_label\"].values\n",
    "    dest_labels = df_graph[\"v_label\"].values\n",
    "    timestamps = df_graph.ts.values\n",
    "\n",
    "    full_data = GraphData(sources=sources, destinations=destinations, timestamps=timestamps, edge_idxs=edge_idxs, source_labels=source_labels, dest_labels=dest_labels)\n",
    "\n",
    "    train_mask = timestamps <= val_time\n",
    "    val_mask = np.logical_and(timestamps <= test_time, timestamps > val_time)\n",
    "    test_mask = timestamps > test_time\n",
    "    train_data = GraphData(\n",
    "      sources=sources[train_mask],\n",
    "      destinations=destinations[train_mask],\n",
    "      timestamps=timestamps[train_mask],\n",
    "      edge_idxs=edge_idxs[train_mask],\n",
    "      source_labels=source_labels[train_mask],\n",
    "      dest_labels=dest_labels[train_mask],\n",
    "      limit=limit,\n",
    "    )\n",
    "    val_data = GraphData(\n",
    "      sources=sources[val_mask],\n",
    "      destinations=destinations[val_mask],\n",
    "      timestamps=timestamps[val_mask],\n",
    "      edge_idxs=edge_idxs[val_mask],\n",
    "      source_labels=source_labels[val_mask],\n",
    "      dest_labels=dest_labels[val_mask],\n",
    "    )\n",
    "    test_data = GraphData(\n",
    "      sources=sources[test_mask],\n",
    "      destinations=destinations[test_mask],\n",
    "      timestamps=timestamps[test_mask],\n",
    "      edge_idxs=edge_idxs[test_mask],\n",
    "      source_labels=source_labels[test_mask],\n",
    "      dest_labels=dest_labels[test_mask],\n",
    "    )\n",
    "    if normalize_features:\n",
    "        # Features and indices setup\n",
    "        features =  [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"CCI\", \"SAR\", \"PSARr\", \"ADX\",\n",
    "                    \"ADX-S\", \"MFI\", \"MFI-S\", \"RSI\", \"RSI-S\", \"SK\", \"SD\", \"BB_Upper\", \"BB_Lower\", \"BB_Mid\",\n",
    "                    \"MACD\", \"MACD_Signal\", \"SAR-S\", \"S-S\", \"CCI-S\", \"Volume_MA5\", \"V-S\", \"CPOP-S\", \"CPCPY-S\"]\n",
    "        features_to_norm = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"CCI\", \"SAR\", \"ADX\", \"MFI\",\n",
    "                            \"RSI\", \"RSI-S\", \"SK\", \"SD\", \"BB_Upper\", \"BB_Lower\", \"BB_Mid\", \"MACD\", \"MACD_Signal\", \"Volume_MA5\"]\n",
    "        feature_indices = [features.index(feat) for feat in features_to_norm]\n",
    "\n",
    "        train_node_indices = np.unique(np.hstack([train_data.sources, train_data.destinations]))\n",
    "        train_timestamp_indices = np.unique(train_data.timestamps)\n",
    "\n",
    "        # 1. Extract training subset of relevant features\n",
    "        train_node_features = node_features[np.ix_(train_node_indices, train_timestamp_indices, feature_indices)]\n",
    "        train_node_features = train_node_features.reshape(-1, len(feature_indices))  # Reshape for MinMaxScaler\n",
    "\n",
    "        # 2. Filter out zero vectors (all-zero rows)\n",
    "        non_zero_train_data = train_node_features[~np.all(train_node_features == 0, axis=1)]\n",
    "\n",
    "        # 3. Fit MinMaxScaler on non-zero training data\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(non_zero_train_data)\n",
    "\n",
    "        #     return tensor\n",
    "        def normalize_features(tensor, node_indices, timestamp_indices):\n",
    "            # Extract the relevant features in a batch\n",
    "            selected_features = tensor[np.ix_(node_indices, timestamp_indices, feature_indices)]\n",
    "\n",
    "            # Reshape for batch transformation and create a mask to keep zero vectors intact\n",
    "            reshaped_selected_features = selected_features.reshape(-1, len(feature_indices))\n",
    "            non_zero_mask = ~np.all(reshaped_selected_features == 0, axis=1)\n",
    "\n",
    "            # Apply transformation only to non-zero rows and clip within [0, 1]\n",
    "            transformed_data = reshaped_selected_features.copy()\n",
    "            transformed_data[non_zero_mask] = scaler.transform(reshaped_selected_features[non_zero_mask])\n",
    "            transformed_data = np.clip(transformed_data, 0, 1)  # Clip to handle numerical instability\n",
    "\n",
    "            # Reshape back and assign transformed data to the tensor\n",
    "            tensor[np.ix_(node_indices, timestamp_indices, feature_indices)] = transformed_data.reshape(selected_features.shape)\n",
    "            return tensor\n",
    "\n",
    "        # 5. Apply normalization on training, validation, and test sets\n",
    "        # Training set\n",
    "        node_features = normalize_features(node_features, train_node_indices, train_timestamp_indices)\n",
    "\n",
    "        # Validation and test sets\n",
    "        valid_node_indices = np.unique(np.hstack([val_data.sources, val_data.destinations]))\n",
    "        valid_timestamp_indices = np.unique(val_data.timestamps)\n",
    "        node_features = normalize_features(node_features, valid_node_indices, valid_timestamp_indices)\n",
    "\n",
    "        test_node_indices = np.unique(np.hstack([test_data.sources, test_data.destinations]))\n",
    "        test_timestamp_indices = np.unique(test_data.timestamps)\n",
    "        node_features = normalize_features(node_features, test_node_indices, test_timestamp_indices)\n",
    "\n",
    "    return node_features, edge_features, full_data, train_data, val_data, test_data\n",
    "\n",
    "def get_neighbor_finder(data: GraphData, uniform: bool = False, max_node_idx: Optional[int] = None) -> NeighborFinder:\n",
    "    max_node_idx = max(data.sources.max(), data.destinations.max()) if max_node_idx is None else max_node_idx\n",
    "    adj_list = [[] for _ in range(max_node_idx + 1)]\n",
    "    for source, destination, edge_idx, timestamp in zip(data.sources, data.destinations,\n",
    "                                                        data.edge_idxs,\n",
    "                                                        data.timestamps):\n",
    "        adj_list[source].append((destination, edge_idx, timestamp))\n",
    "        adj_list[destination].append((source, edge_idx, timestamp))\n",
    "\n",
    "    return NeighborFinder(adj_list, uniform=uniform)\n",
    "\n",
    "def compute_time_statistics(sources: np.ndarray, destinations: np.ndarray, timestamps: np.ndarray) -> Tuple[float, float, float, float]:\n",
    "  last_timestamp_sources = dict()\n",
    "  last_timestamp_dst = dict()\n",
    "  all_timediffs_src = []\n",
    "  all_timediffs_dst = []\n",
    "  for k in range(len(sources)):\n",
    "    source_id = sources[k]\n",
    "    dest_id = destinations[k]\n",
    "    c_timestamp = timestamps[k]\n",
    "    if source_id not in last_timestamp_sources.keys():\n",
    "      last_timestamp_sources[source_id] = 0\n",
    "    if dest_id not in last_timestamp_dst.keys():\n",
    "      last_timestamp_dst[dest_id] = 0\n",
    "    all_timediffs_src.append(c_timestamp - last_timestamp_sources[source_id])\n",
    "    all_timediffs_dst.append(c_timestamp - last_timestamp_dst[dest_id])\n",
    "    last_timestamp_sources[source_id] = c_timestamp\n",
    "    last_timestamp_dst[dest_id] = c_timestamp\n",
    "  assert len(all_timediffs_src) == len(sources)\n",
    "  assert len(all_timediffs_dst) == len(sources)\n",
    "  mean_time_shift_src = np.mean(all_timediffs_src)\n",
    "  std_time_shift_src = np.std(all_timediffs_src)\n",
    "  mean_time_shift_dst = np.mean(all_timediffs_dst)\n",
    "  std_time_shift_dst = np.std(all_timediffs_dst)\n",
    "\n",
    "  return mean_time_shift_src, std_time_shift_src, mean_time_shift_dst, std_time_shift_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fc_4nhx2n4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "!cd drive/MyDrive/tgn-stock && unzip data.zip -d ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrD6_lqC2-6k"
   },
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = Path(\"data/processed/\")\n",
    "PATH_OUTPUT = Path(\"drive/MyDrive/tgn-stock\")\n",
    "\n",
    "assert PATH_OUTPUT.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le9MdYV5sRF1"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "\n",
    "def hyperparam_hash(hyperparams):\n",
    "    # Sort the dictionary to ensure consistent ordering\n",
    "    hyperparams_sorted = json.dumps(hyperparams, sort_keys=True).encode('utf-8')\n",
    "\n",
    "    # Create an MD5 hash object\n",
    "    hash_obj = hashlib.md5(hyperparams_sorted)\n",
    "\n",
    "    # Generate a hexadecimal digest of the hash\n",
    "    hyperparam_hash = hash_obj.hexdigest()\n",
    "\n",
    "    return hyperparam_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlQwZIbG1l85"
   },
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F--lrd5I1l85"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.75\n",
    "TEST_SIZE = 0.20\n",
    "GPU = 0\n",
    "\n",
    "NUM_LAYER = 1\n",
    "NUM_HEADS = 1\n",
    "DROP_OUT = 0.1\n",
    "USE_MEMORY = True\n",
    "MESSAGE_DIM = 16\n",
    "MEMORY_DIM = 16\n",
    "DECODER_HIDDEN_DIM = 32\n",
    "\n",
    "memory_update_at_end = False\n",
    "embedding_module = \"graph_attention\"\n",
    "message_function = \"identity\"\n",
    "aggregator = \"last\"\n",
    "memory_updater = \"gru\"\n",
    "NUM_NEIGHBORS = 2\n",
    "use_destination_embedding_in_message = False\n",
    "use_source_embedding_in_message = False\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 400\n",
    "BACKPROP_EVERY = 1\n",
    "NUM_EPOCH = 50\n",
    "validate_every = 2\n",
    "\n",
    "LIMIT = None # limit dataset for debugging\n",
    "# Define threshold\n",
    "threshold = 0.5\n",
    "normalize_features= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iuhgoFMti-e"
   },
   "outputs": [],
   "source": [
    "parameters = dict(train_size=TRAIN_SIZE,\n",
    "                  test_size=TEST_SIZE,\n",
    "                  gpu=GPU,\n",
    "                  n_layers=NUM_LAYER,\n",
    "                  n_heads=NUM_HEADS,\n",
    "                  dropout=DROP_OUT,\n",
    "                  use_memory=USE_MEMORY,\n",
    "                  message_dim=MESSAGE_DIM,\n",
    "                  memory_dimension=MEMORY_DIM,\n",
    "                  decoder_hidden_dim=DECODER_HIDDEN_DIM,\n",
    "                  memory_update_at_end=memory_update_at_end,\n",
    "                  embedding_module_type=embedding_module,\n",
    "                  message_function=message_function,\n",
    "                  aggregator_type=aggregator,\n",
    "                  memory_updater_type=memory_updater,\n",
    "                  n_neighbors=NUM_NEIGHBORS,\n",
    "                  use_destination_embedding_in_message=use_destination_embedding_in_message,\n",
    "                  use_source_embedding_in_message=use_source_embedding_in_message,\n",
    "                  learning_rate=LEARNING_RATE,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  backprop_every=BACKPROP_EVERY,\n",
    "                  num_epochs=NUM_EPOCH,\n",
    "                  validate_every=validate_every,\n",
    "                  limit=LIMIT,\n",
    "                  threshold=threshold,\n",
    "                  normalize_features=normalize_features,\n",
    "                  )\n",
    "\n",
    "idx = hyperparam_hash(parameters)\n",
    "PATH_OUTPUT = PATH_OUTPUT / idx\n",
    "PATH_OUTPUT.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFGNn72at6oT"
   },
   "outputs": [],
   "source": [
    "PATH_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dsO1v9t1l85"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcgWs6Q71l85"
   },
   "outputs": [],
   "source": [
    "df_graph_version = \"2.0.0\"\n",
    "DATA_PATH = PROCESSED_DATA_DIR / \"graph_dataframes\" / df_graph_version / f\"df_graph_{df_graph_version}.parquet\"\n",
    "FEATURES_PATH = PROCESSED_DATA_DIR / \"feat\" /  df_graph_version / f\"node_feature_vectors_{df_graph_version}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGG8cjFh1l86"
   },
   "outputs": [],
   "source": [
    "node_features, edge_features, full_data, train_data, val_data, test_data = load_data(data_path=DATA_PATH, features_path=FEATURES_PATH, randomize_features=False, train_size=TRAIN_SIZE, test_size=TEST_SIZE, limit=LIMIT, normalize_features=normalize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-PVfoTC1l86"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XV5OTUp1l87"
   },
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUHLKjGH1l87"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6FxzQun1l87"
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKKWPUpR1l87"
   },
   "source": [
    "### Time2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IZPCDRO1l87"
   },
   "outputs": [],
   "source": [
    "class TimeEncode(torch.nn.Module):\n",
    "  # Time Encoding proposed by TGAT\n",
    "  def __init__(self, dimension):\n",
    "    super(TimeEncode, self).__init__()\n",
    "\n",
    "    self.dimension = dimension\n",
    "    self.w = torch.nn.Linear(1, dimension)\n",
    "\n",
    "    self.w.weight = torch.nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, dimension)))\n",
    "                                       .float().reshape(dimension, -1))\n",
    "    self.w.bias = torch.nn.Parameter(torch.zeros(dimension).float())\n",
    "\n",
    "  def forward(self, t):\n",
    "    # t has shape [batch_size, seq_len]\n",
    "    # Add dimension at the end to apply linear layer --> [batch_size, seq_len, 1]\n",
    "    t = t.unsqueeze(dim=2)\n",
    "\n",
    "    # output has shape [batch_size, seq_len, dimension]\n",
    "    output = torch.cos(self.w(t))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-5Ei0cj1l88"
   },
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGoskFF51l88"
   },
   "outputs": [],
   "source": [
    "class Memory(nn.Module):\n",
    "\n",
    "  def __init__(self, n_nodes, memory_dimension, input_dimension, message_dimension=None,\n",
    "               device=\"cpu\", combination_method='sum'):\n",
    "    super(Memory, self).__init__()\n",
    "    self.n_nodes = n_nodes\n",
    "    self.memory_dimension = memory_dimension\n",
    "    self.input_dimension = input_dimension\n",
    "    self.message_dimension = message_dimension\n",
    "    self.device = device\n",
    "\n",
    "    self.combination_method = combination_method\n",
    "\n",
    "    self.__init_memory__()\n",
    "\n",
    "  def __init_memory__(self):\n",
    "    \"\"\"\n",
    "    Initializes the memory to all zeros. It should be called at the start of each epoch.\n",
    "    \"\"\"\n",
    "    # Treat memory as parameter so that it is saved and loaded together with the model\n",
    "    self.memory = nn.Parameter(torch.zeros((self.n_nodes, self.memory_dimension)).to(self.device),\n",
    "                               requires_grad=False)\n",
    "    self.last_update = nn.Parameter(torch.zeros(self.n_nodes).to(self.device),\n",
    "                                    requires_grad=False)\n",
    "\n",
    "    self.messages = defaultdict(list)\n",
    "\n",
    "  def store_raw_messages(self, nodes, node_id_to_messages):\n",
    "    for node in nodes:\n",
    "      self.messages[node].extend(node_id_to_messages[node])\n",
    "\n",
    "  def get_memory(self, node_idxs):\n",
    "    return self.memory[node_idxs, :]\n",
    "\n",
    "  def set_memory(self, node_idxs, values):\n",
    "    self.memory[node_idxs, :] = values\n",
    "\n",
    "  def get_last_update(self, node_idxs):\n",
    "    return self.last_update[node_idxs]\n",
    "\n",
    "  def backup_memory(self):\n",
    "    messages_clone = {}\n",
    "    for k, v in self.messages.items():\n",
    "      messages_clone[k] = [(x[0].clone(), x[1].clone()) for x in v]\n",
    "\n",
    "    return self.memory.data.clone(), self.last_update.data.clone(), messages_clone\n",
    "\n",
    "  def restore_memory(self, memory_backup):\n",
    "    self.memory.data, self.last_update.data = memory_backup[0].clone(), memory_backup[1].clone()\n",
    "\n",
    "    self.messages = defaultdict(list)\n",
    "    for k, v in memory_backup[2].items():\n",
    "      self.messages[k] = [(x[0].clone(), x[1].clone()) for x in v]\n",
    "\n",
    "  def detach_memory(self):\n",
    "    # self.memory.detach_()\n",
    "    self.memory.detach_()\n",
    "\n",
    "    # Detach all stored messages\n",
    "    for k, v in self.messages.items():\n",
    "      new_node_messages = []\n",
    "      for message in v:\n",
    "        new_node_messages.append((message[0].detach(), message[1]))\n",
    "\n",
    "      self.messages[k] = new_node_messages\n",
    "\n",
    "  def clear_messages(self, nodes):\n",
    "    for node in nodes:\n",
    "      self.messages[node] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn6uh0TP1l88"
   },
   "source": [
    "### Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aH6PPL7W1l88"
   },
   "outputs": [],
   "source": [
    "class MessageFunction(nn.Module):\n",
    "  \"\"\"\n",
    "  Module which computes the message for a given interaction.\n",
    "  \"\"\"\n",
    "\n",
    "  def compute_message(self, raw_messages):\n",
    "    return None\n",
    "\n",
    "\n",
    "class MLPMessageFunction(MessageFunction):\n",
    "  def __init__(self, raw_message_dimension, message_dimension):\n",
    "    super(MLPMessageFunction, self).__init__()\n",
    "\n",
    "    self.mlp = self.layers = nn.Sequential(\n",
    "      nn.Linear(raw_message_dimension, raw_message_dimension // 2),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(raw_message_dimension // 2, message_dimension),\n",
    "    )\n",
    "\n",
    "  def compute_message(self, raw_messages):\n",
    "    messages = self.mlp(raw_messages)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "class IdentityMessageFunction(MessageFunction):\n",
    "\n",
    "  def compute_message(self, raw_messages):\n",
    "\n",
    "    return raw_messages\n",
    "\n",
    "\n",
    "def get_message_function(module_type, raw_message_dimension, message_dimension):\n",
    "  if module_type == \"mlp\":\n",
    "    return MLPMessageFunction(raw_message_dimension, message_dimension)\n",
    "  elif module_type == \"identity\":\n",
    "    return IdentityMessageFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk5CICQI1l88"
   },
   "source": [
    "### Message Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_pAlv1S1l88"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class MessageAggregator(ABC, torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Abstract class for the message aggregator module, which given a batch of node ids and\n",
    "  corresponding messages, aggregates messages with the same node id.\n",
    "  \"\"\"\n",
    "  def __init__(self, device):\n",
    "    super(MessageAggregator, self).__init__()\n",
    "    self.device = device\n",
    "\n",
    "  @abstractmethod\n",
    "  def aggregate(self, node_ids, messages):\n",
    "    \"\"\"\n",
    "    Given a list of node ids, and a list of messages of the same length, aggregate different\n",
    "    messages for the same id using one of the possible strategies.\n",
    "    :param node_ids: A list of node ids of length batch_size\n",
    "    :param messages: A tensor of shape [batch_size, message_length]\n",
    "    :param timestamps A tensor of shape [batch_size]\n",
    "    :return: A tensor of shape [n_unique_node_ids, message_length] with the aggregated messages\n",
    "    \"\"\"\n",
    "    return NotImplementedError()\n",
    "\n",
    "  def group_by_id(self, node_ids, messages, timestamps):\n",
    "    node_id_to_messages = defaultdict(list)\n",
    "\n",
    "    for i, node_id in enumerate(node_ids):\n",
    "      node_id_to_messages[node_id].append((messages[i], timestamps[i]))\n",
    "\n",
    "    return node_id_to_messages\n",
    "\n",
    "\n",
    "class LastMessageAggregator(MessageAggregator):\n",
    "  def __init__(self, device):\n",
    "    super(LastMessageAggregator, self).__init__(device)\n",
    "\n",
    "  def aggregate(self, node_ids, messages):\n",
    "    \"\"\"Only keep the last message for each node\"\"\"\n",
    "    unique_node_ids = np.unique(node_ids)\n",
    "    unique_messages = []\n",
    "    unique_timestamps = []\n",
    "\n",
    "    to_update_node_ids = []\n",
    "\n",
    "    for node_id in unique_node_ids:\n",
    "        if len(messages[node_id]) > 0:\n",
    "            to_update_node_ids.append(node_id)\n",
    "            unique_messages.append(messages[node_id][-1][0])\n",
    "            unique_timestamps.append(messages[node_id][-1][1])\n",
    "\n",
    "    unique_messages = torch.stack(unique_messages) if len(to_update_node_ids) > 0 else []\n",
    "    unique_timestamps = torch.stack(unique_timestamps) if len(to_update_node_ids) > 0 else []\n",
    "\n",
    "    return to_update_node_ids, unique_messages, unique_timestamps\n",
    "\n",
    "\n",
    "class MeanMessageAggregator(MessageAggregator):\n",
    "  def __init__(self, device):\n",
    "    super(MeanMessageAggregator, self).__init__(device)\n",
    "\n",
    "  def aggregate(self, node_ids, messages):\n",
    "    unique_node_ids = np.unique(node_ids)\n",
    "    unique_messages = []\n",
    "    unique_timestamps = []\n",
    "\n",
    "    to_update_node_ids = []\n",
    "    n_messages = 0\n",
    "\n",
    "    for node_id in unique_node_ids:\n",
    "      if len(messages[node_id]) > 0:\n",
    "        n_messages += len(messages[node_id])\n",
    "        to_update_node_ids.append(node_id)\n",
    "        unique_messages.append(torch.mean(torch.stack([m[0] for m in messages[node_id]]), dim=0))\n",
    "        unique_timestamps.append(messages[node_id][-1][1])\n",
    "\n",
    "    unique_messages = torch.stack(unique_messages) if len(to_update_node_ids) > 0 else []\n",
    "    unique_timestamps = torch.stack(unique_timestamps) if len(to_update_node_ids) > 0 else []\n",
    "\n",
    "    return to_update_node_ids, unique_messages, unique_timestamps\n",
    "\n",
    "\n",
    "def get_message_aggregator(aggregator_type, device):\n",
    "  if aggregator_type == \"last\":\n",
    "    return LastMessageAggregator(device=device)\n",
    "  elif aggregator_type == \"mean\":\n",
    "    return MeanMessageAggregator(device=device)\n",
    "  else:\n",
    "    raise ValueError(\"Message aggregator {} not implemented\".format(aggregator_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e20_Z2yp1l88"
   },
   "source": [
    "### Memory Updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjIjr7T_1l88"
   },
   "outputs": [],
   "source": [
    "class MemoryUpdater(ABC, nn.Module):\n",
    "\n",
    "  @abstractmethod\n",
    "  def update_memory(self, unique_node_ids, unique_messages, timestamps):\n",
    "    return NotImplementedError()\n",
    "\n",
    "\n",
    "class SequenceMemoryUpdater(MemoryUpdater):\n",
    "  def __init__(self, memory, message_dimension, memory_dimension, device):\n",
    "    super(SequenceMemoryUpdater, self).__init__()\n",
    "    self.memory = memory\n",
    "    self.layer_norm = torch.nn.LayerNorm(memory_dimension)\n",
    "    self.message_dimension = message_dimension\n",
    "    self.device = device\n",
    "\n",
    "  def update_memory(self, unique_node_ids, unique_messages, timestamps):\n",
    "    if len(unique_node_ids) <= 0:\n",
    "      return\n",
    "\n",
    "    assert (self.memory.get_last_update(unique_node_ids) <= timestamps).all().item(), \"Trying to \" \\\n",
    "                                                                                     \"update memory to time in the past\"\n",
    "\n",
    "    memory = self.memory.get_memory(unique_node_ids)\n",
    "    self.memory.last_update[unique_node_ids] = timestamps\n",
    "\n",
    "    updated_memory = self.memory_updater(unique_messages, memory)\n",
    "\n",
    "    self.memory.set_memory(unique_node_ids, updated_memory)\n",
    "\n",
    "  def get_updated_memory(self, unique_node_ids, unique_messages, timestamps):\n",
    "    if len(unique_node_ids) <= 0:\n",
    "      return self.memory.memory.data.clone(), self.memory.last_update.data.clone()\n",
    "\n",
    "    assert (self.memory.get_last_update(unique_node_ids) <= timestamps).all().item(), \"Trying to \" \\\n",
    "                                                                                     \"update memory to time in the past\"\n",
    "\n",
    "    updated_memory = self.memory.memory.data.clone()\n",
    "    updated_memory[unique_node_ids] = self.memory_updater(unique_messages, updated_memory[unique_node_ids])\n",
    "\n",
    "    updated_last_update = self.memory.last_update.data.clone()\n",
    "    updated_last_update[unique_node_ids] = timestamps\n",
    "\n",
    "    return updated_memory, updated_last_update\n",
    "\n",
    "\n",
    "class GRUMemoryUpdater(SequenceMemoryUpdater):\n",
    "  def __init__(self, memory, message_dimension, memory_dimension, device):\n",
    "    super(GRUMemoryUpdater, self).__init__(memory, message_dimension, memory_dimension, device)\n",
    "\n",
    "    self.memory_updater = nn.GRUCell(input_size=message_dimension,\n",
    "                                     hidden_size=memory_dimension)\n",
    "\n",
    "class RNNMemoryUpdater(SequenceMemoryUpdater):\n",
    "  def __init__(self, memory, message_dimension, memory_dimension, device):\n",
    "    super(RNNMemoryUpdater, self).__init__(memory, message_dimension, memory_dimension, device)\n",
    "\n",
    "    self.memory_updater = nn.RNNCell(input_size=message_dimension,\n",
    "                                     hidden_size=memory_dimension)\n",
    "\n",
    "class LSTMMemoryUpdater(SequenceMemoryUpdater):\n",
    "    def __init__(self, memory, message_dimension, memory_dimension, device):\n",
    "        super(LSTMMemoryUpdater, self).__init__(memory, message_dimension, memory_dimension, device)\n",
    "\n",
    "        self.memory_updater = nn.LSTMCell(input_size=message_dimension,\n",
    "                                          hidden_size=memory_dimension)\n",
    "\n",
    "        # Initialize hidden and cell states for the LSTM\n",
    "        self.hidden_states = torch.zeros(memory.memory.size(0), memory_dimension, device=device)\n",
    "        self.cell_states = torch.zeros(memory.memory.size(0), memory_dimension, device=device)\n",
    "\n",
    "    def update_memory(self, unique_node_ids, unique_messages, timestamps):\n",
    "        if len(unique_node_ids) <= 0:\n",
    "            return\n",
    "\n",
    "        assert (self.memory.get_last_update(unique_node_ids) <= timestamps).all().item(), \"Trying to \" \\\n",
    "                                                                                         \"update memory to time in the past\"\n",
    "\n",
    "        # Retrieve current memory (hidden states) and cell states\n",
    "        memory = self.memory.get_memory(unique_node_ids)  # This corresponds to h_t\n",
    "        cell_states = self.cell_states[unique_node_ids]   # Retrieve c_t\n",
    "\n",
    "        self.memory.last_update[unique_node_ids] = timestamps\n",
    "\n",
    "        # Update LSTM memory\n",
    "        updated_hidden_states, updated_cell_states = self.memory_updater(unique_messages, (memory, cell_states))\n",
    "\n",
    "        # Store the updated hidden states back as memory\n",
    "        self.memory.set_memory(unique_node_ids, updated_hidden_states)\n",
    "\n",
    "        # Update the LSTM's internal cell states\n",
    "        self.cell_states[unique_node_ids] = updated_cell_states\n",
    "\n",
    "    def get_updated_memory(self, unique_node_ids, unique_messages, timestamps):\n",
    "        if len(unique_node_ids) <= 0:\n",
    "            return self.memory.memory.data.clone(), self.memory.last_update.data.clone()\n",
    "\n",
    "        assert (self.memory.get_last_update(unique_node_ids) <= timestamps).all().item(), \"Trying to \" \\\n",
    "                                                                                         \"update memory to time in the past\"\n",
    "\n",
    "        # Clone the current memory and internal states\n",
    "        updated_memory = self.memory.memory.data.clone()\n",
    "        updated_cell_states = self.cell_states.data.clone()\n",
    "\n",
    "        # Update LSTM memory\n",
    "        new_hidden_states, new_cell_states = self.memory_updater(unique_messages,\n",
    "                                                                 (updated_memory[unique_node_ids],\n",
    "                                                                  updated_cell_states[unique_node_ids]))\n",
    "\n",
    "        # Update the cloned memory\n",
    "        updated_memory[unique_node_ids] = new_hidden_states\n",
    "\n",
    "        # Update internal cell states\n",
    "        updated_cell_states[unique_node_ids] = new_cell_states\n",
    "\n",
    "        # Clone the last update timestamps\n",
    "        updated_last_update = self.memory.last_update.data.clone()\n",
    "        updated_last_update[unique_node_ids] = timestamps\n",
    "\n",
    "        return updated_memory, updated_last_update\n",
    "\n",
    "def get_memory_updater(module_type, memory, message_dimension, memory_dimension, device):\n",
    "    if module_type == \"gru\":\n",
    "        return GRUMemoryUpdater(memory, message_dimension, memory_dimension, device)\n",
    "    elif module_type == \"rnn\":\n",
    "        return RNNMemoryUpdater(memory, message_dimension, memory_dimension, device)\n",
    "    elif module_type == \"lstm\":\n",
    "        return LSTMMemoryUpdater(memory, message_dimension, memory_dimension, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dS7tQ6P1l89"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7inE7ig1l89"
   },
   "source": [
    "#### Temporal Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkdVqyPz1l89"
   },
   "outputs": [],
   "source": [
    "class MergeLayer(torch.nn.Module):\n",
    "  def __init__(self, dim1, dim2, dim3, dim4):\n",
    "    super().__init__()\n",
    "    self.fc1 = torch.nn.Linear(dim1 + dim2, dim3)\n",
    "    self.fc2 = torch.nn.Linear(dim3, dim4)\n",
    "    self.act = torch.nn.ReLU()\n",
    "\n",
    "    torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "    torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "    x = torch.cat([x1, x2], dim=1)\n",
    "    h = self.act(self.fc1(x))\n",
    "    return self.fc2(h)\n",
    "\n",
    "class NodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_node_features, hidden_dim, out_dim=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_node_features, hidden_dim)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_dim)          # Batch normalization after first layer\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_dim * 2)      # Batch normalization after second layer\n",
    "        self.fc_out = torch.nn.Linear(hidden_dim * 2, out_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)        # Dropout layer\n",
    "        self.act = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.bn1(self.fc1(x)))       # Apply batch norm and activation after fc1\n",
    "        h = self.dropout(h)                       # Apply dropout\n",
    "        h = self.act(self.bn2(self.fc2(h)))       # Apply batch norm and activation after fc2\n",
    "        h = self.dropout(h)                       # Apply dropout\n",
    "        return self.fc_out(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eh3929Qa1l89"
   },
   "outputs": [],
   "source": [
    "class TemporalAttentionLayer(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Temporal attention layer. Return the temporal embedding of a node given the node itself,\n",
    "   its neighbors and the edge timestamps.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, n_node_features, n_neighbors_features, n_edge_features, time_dim,\n",
    "               output_dimension, n_head=2,\n",
    "               dropout=0.1):\n",
    "    super(TemporalAttentionLayer, self).__init__()\n",
    "\n",
    "    self.n_head = n_head\n",
    "\n",
    "    self.time_dim = time_dim\n",
    "    self.query_dim = n_node_features + time_dim\n",
    "    self.key_dim = n_neighbors_features + time_dim + n_edge_features\n",
    "\n",
    "    self.merger = MergeLayer(self.query_dim, n_node_features, n_node_features, output_dimension)\n",
    "\n",
    "    self.multi_head_target = nn.MultiheadAttention(embed_dim=self.query_dim,\n",
    "                                                   kdim=self.key_dim,\n",
    "                                                   vdim=self.key_dim,\n",
    "                                                   num_heads=n_head,\n",
    "                                                   dropout=dropout)\n",
    "\n",
    "  def forward(self, src_node_features, src_time_features, neighbors_features,\n",
    "              neighbors_time_features, edge_features, neighbors_padding_mask):\n",
    "    \"\"\"\n",
    "    \"Temporal attention model\n",
    "    :param src_node_features: float Tensor of shape [batch_size, n_node_features]\n",
    "    :param src_time_features: float Tensor of shape [batch_size, 1, time_dim]\n",
    "    :param neighbors_features: float Tensor of shape [batch_size, n_neighbors, n_node_features]\n",
    "    :param neighbors_time_features: float Tensor of shape [batch_size, n_neighbors,\n",
    "    time_dim]\n",
    "    :param edge_features: float Tensor of shape [batch_size, n_neighbors, n_edge_features]\n",
    "    :param neighbors_padding_mask: float Tensor of shape [batch_size, n_neighbors]\n",
    "    :return:\n",
    "    attn_output: float Tensor of shape [1, batch_size, n_node_features]\n",
    "    attn_output_weights: [batch_size, 1, n_neighbors]\n",
    "    \"\"\"\n",
    "\n",
    "    src_node_features_unrolled = torch.unsqueeze(src_node_features, dim=1)\n",
    "\n",
    "    query = torch.cat([src_node_features_unrolled, src_time_features], dim=2)\n",
    "    key = torch.cat([neighbors_features, edge_features, neighbors_time_features], dim=2)\n",
    "\n",
    "    # Reshape tensors so to expected shape by multi head attention\n",
    "    query = query.permute([1, 0, 2])  # [1, batch_size, num_of_features]\n",
    "    key = key.permute([1, 0, 2])  # [n_neighbors, batch_size, num_of_features]\n",
    "\n",
    "    # Compute mask of which source nodes have no valid neighbors\n",
    "    invalid_neighborhood_mask = neighbors_padding_mask.all(dim=1, keepdim=True)\n",
    "    # If a source node has no valid neighbor, set it's first neighbor to be valid. This will\n",
    "    # force the attention to just 'attend' on this neighbor (which has the same features as all\n",
    "    # the others since they are fake neighbors) and will produce an equivalent result to the\n",
    "    # original tgat paper which was forcing fake neighbors to all have same attention of 1e-10\n",
    "    neighbors_padding_mask[invalid_neighborhood_mask.squeeze(), 0] = False\n",
    "\n",
    "    attn_output, attn_output_weights = self.multi_head_target(query=query, key=key, value=key,\n",
    "                                                              key_padding_mask=neighbors_padding_mask)\n",
    "\n",
    "\n",
    "    attn_output = attn_output.squeeze()\n",
    "    attn_output_weights = attn_output_weights.squeeze()\n",
    "\n",
    "    # Source nodes with no neighbors have an all zero attention output. The attention output is\n",
    "    # then added or concatenated to the original source node features and then fed into an MLP.\n",
    "    # This means that an all zero vector is not used.\n",
    "    attn_output = attn_output.masked_fill(invalid_neighborhood_mask, 0)\n",
    "    attn_output_weights = attn_output_weights.masked_fill(invalid_neighborhood_mask, 0)\n",
    "\n",
    "    # Skip connection with temporal attention over neighborhood and the features of the node itself\n",
    "    attn_output = self.merger(attn_output, src_node_features)\n",
    "\n",
    "    return attn_output, attn_output_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svk6618T1l89"
   },
   "source": [
    "#### Different types of Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhXlsQN61l89"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class EmbeddingModule(ABC, nn.Module):\n",
    "  def __init__(self, node_features, edge_features, memory, neighbor_finder, time_encoder, n_layers,\n",
    "               n_node_features, n_edge_features, n_time_features, embedding_dimension, device,\n",
    "               dropout):\n",
    "    super(EmbeddingModule, self).__init__()\n",
    "    self.node_features = node_features\n",
    "    self.edge_features = edge_features\n",
    "    self.memory = memory\n",
    "    self.neighbor_finder = neighbor_finder\n",
    "    self.time_encoder = time_encoder\n",
    "    self.n_layers = n_layers\n",
    "    self.n_node_features = n_node_features\n",
    "    self.n_edge_features = n_edge_features\n",
    "    self.n_time_features = n_time_features\n",
    "    self.dropout = dropout\n",
    "    self.embedding_dimension = embedding_dimension\n",
    "    self.device = device\n",
    "\n",
    "  @abstractmethod\n",
    "  def compute_embedding(self, memory, source_nodes, timestamps, n_layers, n_neighbors=20, time_diffs=None,\n",
    "                        use_time_proj=True):\n",
    "    return NotImplementedError()\n",
    "\n",
    "\n",
    "class IdentityEmbedding(EmbeddingModule):\n",
    "  def compute_embedding(self, memory, source_nodes, timestamps, n_layers, n_neighbors=20, time_diffs=None,\n",
    "                        use_time_proj=True):\n",
    "    return memory[source_nodes, :]\n",
    "\n",
    "\n",
    "class TimeEmbedding(EmbeddingModule):\n",
    "  def __init__(self, node_features, edge_features, memory, neighbor_finder, time_encoder, n_layers,\n",
    "               n_node_features, n_edge_features, n_time_features, embedding_dimension, device,\n",
    "               n_heads=2, dropout=0.1, use_memory=True, n_neighbors=1):\n",
    "    super(TimeEmbedding, self).__init__(node_features, edge_features, memory,\n",
    "                                        neighbor_finder, time_encoder, n_layers,\n",
    "                                        n_node_features, n_edge_features, n_time_features,\n",
    "                                        embedding_dimension, device, dropout)\n",
    "\n",
    "    class NormalLinear(nn.Linear):\n",
    "      # From Jodie code\n",
    "      def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.normal_(0, stdv)\n",
    "        if self.bias is not None:\n",
    "          self.bias.data.normal_(0, stdv)\n",
    "\n",
    "    self.embedding_layer = NormalLinear(1, self.n_node_features)\n",
    "\n",
    "  def compute_embedding(self, memory, source_nodes, timestamps, n_layers, n_neighbors=20, time_diffs=None,\n",
    "                        use_time_proj=True):\n",
    "    source_embeddings = memory[source_nodes, :] * (1 + self.embedding_layer(time_diffs.unsqueeze(1)))\n",
    "\n",
    "    return source_embeddings\n",
    "\n",
    "\n",
    "class GraphEmbedding(EmbeddingModule):\n",
    "\tdef __init__(self, node_features, edge_features, memory, neighbor_finder, time_encoder, n_layers,\n",
    "\t\t\t\tn_node_features, n_edge_features, n_time_features, embedding_dimension, device,\n",
    "\t\t\t\tn_heads=2, dropout=0.1, use_memory=True):\n",
    "\t\tsuper(GraphEmbedding, self).__init__(node_features, edge_features, memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tneighbor_finder, time_encoder, n_layers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tn_node_features, n_edge_features, n_time_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tembedding_dimension, device, dropout)\n",
    "\n",
    "\t\tself.use_memory = use_memory\n",
    "\t\tself.device = device\n",
    "\n",
    "\tdef compute_embedding(self, memory, source_nodes, timestamps, n_layers, n_neighbors=20, time_diffs=None,\n",
    "                        use_time_proj=True):\n",
    "\t\t\"\"\"Recursive implementation of curr_layers temporal graph attention layers.\n",
    "\n",
    "\t\tsrc_idx_l [batch_size]: users / items input ids.\n",
    "\t\tcut_time_l [batch_size]: scalar representing the instant of the time where we want to extract the user / item representation.\n",
    "\t\tcurr_layers [scalar]: number of temporal convolutional layers to stack.\n",
    "\t\tnum_neighbors [scalar]: number of temporal neighbor to consider in each convolutional layer.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tassert (n_layers >= 0)\n",
    "\n",
    "\t\tsource_nodes_torch = torch.from_numpy(source_nodes).long().to(self.device)\n",
    "\t\ttimestamps_torch = torch.unsqueeze(torch.from_numpy(timestamps).float().to(self.device), dim=1)\n",
    "\n",
    "\t\t# query node always has the start time -> time span == 0\n",
    "\t\tsource_nodes_time_embedding = self.time_encoder(torch.zeros_like(\n",
    "\t\ttimestamps_torch))\n",
    "\n",
    "\t\t# source_node_features = self.node_features[source_nodes_torch, :]\n",
    "\t\tsource_node_features = self.node_features[source_nodes_torch, torch.from_numpy(timestamps).long(), :]\n",
    "\n",
    "\t\tif self.use_memory:\n",
    "\t\t\t# Note: We combined memory and node features by concatenating them. In the original paper, authors sum them\n",
    "\t\t\tsource_node_features = torch.cat([memory[source_nodes, :], source_node_features], dim=-1)\n",
    "\n",
    "\t\tif n_layers == 0:\n",
    "\t\t\treturn source_node_features\n",
    "\t\telse:\n",
    "\t\t\tsource_node_conv_embeddings = self.compute_embedding(memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimestamps,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_layers=n_layers - 1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_neighbors=n_neighbors)\n",
    "\n",
    "\t\t\tneighbors, edge_idxs, edge_times = self.neighbor_finder.get_temporal_neighbor(\n",
    "\t\t\t\tsource_nodes,\n",
    "\t\t\t\ttimestamps,\n",
    "\t\t\t\tn_neighbors=n_neighbors)\n",
    "\n",
    "\t\t\tneighbors_torch = torch.from_numpy(neighbors).long().to(self.device)\n",
    "\n",
    "\t\t\tedge_idxs = torch.from_numpy(edge_idxs).long().to(self.device)\n",
    "\n",
    "\t\t\tedge_deltas = timestamps[:, np.newaxis] - edge_times\n",
    "\n",
    "\t\t\tedge_deltas_torch = torch.from_numpy(edge_deltas).float().to(self.device)\n",
    "\n",
    "\t\t\tneighbors = neighbors.flatten()\n",
    "\t\t\tneighbor_embeddings = self.compute_embedding(memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tneighbors,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnp.repeat(timestamps, n_neighbors),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_layers=n_layers - 1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_neighbors=n_neighbors)\n",
    "\n",
    "\t\t\teffective_n_neighbors = n_neighbors if n_neighbors > 0 else 1\n",
    "\t\t\tneighbor_embeddings = neighbor_embeddings.view(len(source_nodes), effective_n_neighbors, -1)\n",
    "\t\t\tedge_time_embeddings = self.time_encoder(edge_deltas_torch)\n",
    "\n",
    "\t\t\tedge_features = self.edge_features[edge_idxs, :]\n",
    "\n",
    "\t\t\tmask = neighbors_torch == 0\n",
    "\t\t\tsource_embedding = self.aggregate(n_layers, source_node_conv_embeddings,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsource_nodes_time_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tneighbor_embeddings,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tedge_time_embeddings,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tedge_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmask)\n",
    "\n",
    "\t\t\treturn source_embedding\n",
    "\n",
    "\tdef aggregate(self, n_layers, source_node_features, source_nodes_time_embedding,\n",
    "\t\t\t\tneighbor_embeddings,\n",
    "\t\t\t\tedge_time_embeddings, edge_features, mask):\n",
    "\t\treturn NotImplemented\n",
    "\n",
    "\n",
    "class GraphSumEmbedding(GraphEmbedding):\n",
    "  def __init__(self, node_features, edge_features, memory, neighbor_finder, time_encoder, n_layers,\n",
    "               n_node_features, n_edge_features, n_time_features, embedding_dimension, device,\n",
    "               n_heads=2, dropout=0.1, use_memory=True):\n",
    "    super(GraphSumEmbedding, self).__init__(node_features=node_features,\n",
    "                                            edge_features=edge_features,\n",
    "                                            memory=memory,\n",
    "                                            neighbor_finder=neighbor_finder,\n",
    "                                            time_encoder=time_encoder, n_layers=n_layers,\n",
    "                                            n_node_features=n_node_features,\n",
    "                                            n_edge_features=n_edge_features,\n",
    "                                            n_time_features=n_time_features,\n",
    "                                            embedding_dimension=embedding_dimension,\n",
    "                                            device=device,\n",
    "                                            n_heads=n_heads, dropout=dropout,\n",
    "                                            use_memory=use_memory)\n",
    "    self.linear_1 = torch.nn.ModuleList([torch.nn.Linear(embedding_dimension + n_time_features +\n",
    "                                                         n_edge_features, embedding_dimension)\n",
    "                                         for _ in range(n_layers)])\n",
    "    self.linear_2 = torch.nn.ModuleList(\n",
    "      [torch.nn.Linear(embedding_dimension + n_node_features + n_time_features,\n",
    "                       embedding_dimension) for _ in range(n_layers)])\n",
    "\n",
    "  def aggregate(self, n_layer, source_node_features, source_nodes_time_embedding,\n",
    "                neighbor_embeddings,\n",
    "                edge_time_embeddings, edge_features, mask):\n",
    "    neighbors_features = torch.cat([neighbor_embeddings, edge_time_embeddings, edge_features],\n",
    "                                   dim=2)\n",
    "    neighbor_embeddings = self.linear_1[n_layer - 1](neighbors_features)\n",
    "    neighbors_sum = torch.nn.functional.relu(torch.sum(neighbor_embeddings, dim=1))\n",
    "\n",
    "    source_features = torch.cat([source_node_features,\n",
    "                                 source_nodes_time_embedding.squeeze()], dim=1)\n",
    "    source_embedding = torch.cat([neighbors_sum, source_features], dim=1)\n",
    "    source_embedding = self.linear_2[n_layer - 1](source_embedding)\n",
    "\n",
    "    return source_embedding\n",
    "\n",
    "\n",
    "class GraphAttentionEmbedding(GraphEmbedding):\n",
    "\tdef __init__(self, node_features, edge_features, memory, neighbor_finder, time_encoder, n_layers,\n",
    "               n_node_features, n_edge_features, n_time_features, embedding_dimension, device,\n",
    "               n_heads=2, dropout=0.1, use_memory=True):\n",
    "\t\tsuper(GraphAttentionEmbedding, self).__init__(node_features, edge_features, memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tneighbor_finder, time_encoder, n_layers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_node_features, n_edge_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_time_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tembedding_dimension, device,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_heads, dropout,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tuse_memory)\n",
    "\n",
    "\t\tself.attention_models = torch.nn.ModuleList([TemporalAttentionLayer(\n",
    "\t\t\tn_node_features=n_node_features + self.memory.memory_dimension,\n",
    "\t\t\tn_neighbors_features=n_node_features + self.memory.memory_dimension,\n",
    "\t\t\tn_edge_features=n_edge_features,\n",
    "\t\t\ttime_dim=n_time_features,\n",
    "\t\t\tn_head=n_heads,\n",
    "\t\t\tdropout=dropout,\n",
    "\t\t\toutput_dimension=n_node_features)\n",
    "\t\t\tfor _ in range(n_layers)])\n",
    "\n",
    "\tdef aggregate(self, n_layer, source_node_features, source_nodes_time_embedding, neighbor_embeddings, edge_time_embeddings, edge_features, mask):\n",
    "\t\tattention_model = self.attention_models[n_layer - 1]\n",
    "\n",
    "\t\tq = source_node_features.shape[1] + source_nodes_time_embedding.shape[2]\n",
    "\t\tk = neighbor_embeddings.shape[2] + edge_time_embeddings.shape[2] + edge_features.shape[2]\n",
    "\n",
    "\t\tsource_embedding, _ = attention_model(source_node_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\tsource_nodes_time_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\tneighbor_embeddings,\n",
    "\t\t\t\t\t\t\t\t\t\t\tedge_time_embeddings,\n",
    "\t\t\t\t\t\t\t\t\t\t\tedge_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmask)\n",
    "\n",
    "\t\treturn source_embedding\n",
    "\n",
    "\n",
    "def get_embedding_module(module_type, node_features, edge_features, memory, neighbor_finder,\n",
    "                         time_encoder, n_layers, n_node_features, n_edge_features, n_time_features,\n",
    "                         embedding_dimension, device,\n",
    "                         n_heads=2, dropout=0.1, n_neighbors=None,\n",
    "                         use_memory=True):\n",
    "  if module_type == \"graph_attention\":\n",
    "    return GraphAttentionEmbedding(node_features=node_features,\n",
    "                                    edge_features=edge_features,\n",
    "                                    memory=memory,\n",
    "                                    neighbor_finder=neighbor_finder,\n",
    "                                    time_encoder=time_encoder,\n",
    "                                    n_layers=n_layers,\n",
    "                                    n_node_features=n_node_features,\n",
    "                                    n_edge_features=n_edge_features,\n",
    "                                    n_time_features=n_time_features,\n",
    "                                    embedding_dimension=embedding_dimension,\n",
    "                                    device=device,\n",
    "                                    n_heads=n_heads, dropout=dropout, use_memory=use_memory)\n",
    "  elif module_type == \"graph_sum\":\n",
    "    return GraphSumEmbedding(node_features=node_features,\n",
    "                              edge_features=edge_features,\n",
    "                              memory=memory,\n",
    "                              neighbor_finder=neighbor_finder,\n",
    "                              time_encoder=time_encoder,\n",
    "                              n_layers=n_layers,\n",
    "                              n_node_features=n_node_features,\n",
    "                              n_edge_features=n_edge_features,\n",
    "                              n_time_features=n_time_features,\n",
    "                              embedding_dimension=embedding_dimension,\n",
    "                              device=device,\n",
    "                              n_heads=n_heads, dropout=dropout, use_memory=use_memory)\n",
    "\n",
    "  elif module_type == \"identity\":\n",
    "    return IdentityEmbedding(node_features=node_features,\n",
    "                             edge_features=edge_features,\n",
    "                             memory=memory,\n",
    "                             neighbor_finder=neighbor_finder,\n",
    "                             time_encoder=time_encoder,\n",
    "                             n_layers=n_layers,\n",
    "                             n_node_features=n_node_features,\n",
    "                             n_edge_features=n_edge_features,\n",
    "                             n_time_features=n_time_features,\n",
    "                             embedding_dimension=embedding_dimension,\n",
    "                             device=device,\n",
    "                             dropout=dropout)\n",
    "  elif module_type == \"time\":\n",
    "    return TimeEmbedding(node_features=node_features,\n",
    "                         edge_features=edge_features,\n",
    "                         memory=memory,\n",
    "                         neighbor_finder=neighbor_finder,\n",
    "                         time_encoder=time_encoder,\n",
    "                         n_layers=n_layers,\n",
    "                         n_node_features=n_node_features,\n",
    "                         n_edge_features=n_edge_features,\n",
    "                         n_time_features=n_time_features,\n",
    "                         embedding_dimension=embedding_dimension,\n",
    "                         device=device,\n",
    "                         dropout=dropout,\n",
    "                         n_neighbors=n_neighbors)\n",
    "  else:\n",
    "    raise ValueError(\"Embedding Module {} not supported\".format(module_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC_zEcMc1l8-"
   },
   "source": [
    "### TGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joChc1Gq1l8-"
   },
   "outputs": [],
   "source": [
    "class TGN(torch.nn.Module):\n",
    "\tdef __init__(self, neighbor_finder, node_features, edge_features, device, n_layers=2,\n",
    "\t\t\t\tn_heads=2, dropout=0.1, use_memory=True,\n",
    "\t\t\t\tmemory_update_at_start=True, message_dimension=100,\n",
    "\t\t\t\tmemory_dimension=500, embedding_module_type=\"graph_attention\",\n",
    "\t\t\t\tmessage_function=\"mlp\",\n",
    "\t\t\t\tmean_time_shift_src=0, std_time_shift_src=1, mean_time_shift_dst=0,\n",
    "\t\t\t\tstd_time_shift_dst=1, n_neighbors=None, aggregator_type=\"last\",\n",
    "\t\t\t\tmemory_updater_type=\"gru\",\n",
    "\t\t\t\tuse_destination_embedding_in_message=False,\n",
    "\t\t\t\tuse_source_embedding_in_message=False,\n",
    "\t\t\t\tdecoder_hidden_dim=32,\n",
    "\t\t\t):\n",
    "\t\tsuper(TGN, self).__init__()\n",
    "\n",
    "\t\tself.n_layers = n_layers\n",
    "\t\tself.neighbor_finder = neighbor_finder\n",
    "\t\tself.device = device\n",
    "\t\tself.logger = logger\n",
    "\n",
    "\t\tself.node_raw_features = torch.from_numpy(node_features.astype(np.float32)).to(device)\n",
    "\t\tself.edge_raw_features = torch.from_numpy(edge_features.astype(np.float32)).to(device)\n",
    "\n",
    "\t\t# Feature array has shape (n_nodes, timestamps_idx, feature_shape)\n",
    "\t\tself.n_node_features = self.node_raw_features.shape[2]\n",
    "\t\tself.n_nodes = self.node_raw_features.shape[0]\n",
    "\t\tself.n_edge_features = self.edge_raw_features.shape[1]\n",
    "\t\tself.embedding_dimension = self.n_node_features\n",
    "\t\tself.n_neighbors = n_neighbors\n",
    "\t\tself.embedding_module_type = embedding_module_type\n",
    "\t\tself.use_destination_embedding_in_message = use_destination_embedding_in_message\n",
    "\t\tself.use_source_embedding_in_message = use_source_embedding_in_message\n",
    "\n",
    "\t\tself.use_memory = use_memory\n",
    "\t\tself.time_encoder = TimeEncode(dimension=self.n_node_features)\n",
    "\t\tself.memory = None\n",
    "\n",
    "\t\tself.mean_time_shift_src = mean_time_shift_src\n",
    "\t\tself.std_time_shift_src = std_time_shift_src\n",
    "\t\tself.mean_time_shift_dst = mean_time_shift_dst\n",
    "\t\tself.std_time_shift_dst = std_time_shift_dst\n",
    "\n",
    "\t\tif self.use_memory:\n",
    "\t\t\tself.memory_dimension = memory_dimension\n",
    "\t\t\tself.memory_update_at_start = memory_update_at_start\n",
    "\t\t\traw_message_dimension = 2 * self.memory_dimension + self.n_edge_features + \\\n",
    "\t\t\t\t\t\t\t\t\tself.time_encoder.dimension\n",
    "\t\t\tmessage_dimension = message_dimension if message_function != \"identity\" else raw_message_dimension\n",
    "\t\t\tself.memory = Memory(n_nodes=self.n_nodes,\n",
    "\t\t\t\t\t\t\t\tmemory_dimension=self.memory_dimension,\n",
    "\t\t\t\t\t\t\t\tinput_dimension=message_dimension,\n",
    "\t\t\t\t\t\t\t\tmessage_dimension=message_dimension,\n",
    "\t\t\t\t\t\t\t\tdevice=device)\n",
    "\t\t\tself.message_aggregator = get_message_aggregator(aggregator_type=aggregator_type,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdevice=device)\n",
    "\t\t\tself.message_function = get_message_function(module_type=message_function,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\traw_message_dimension=raw_message_dimension,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmessage_dimension=message_dimension)\n",
    "\t\t\tself.memory_updater = get_memory_updater(module_type=memory_updater_type,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmemory=self.memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmessage_dimension=message_dimension,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmemory_dimension=self.memory_dimension,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tdevice=device)\n",
    "\n",
    "\t\tself.embedding_module_type = embedding_module_type\n",
    "\t\tself.embedding_module = get_embedding_module(module_type=embedding_module_type,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tnode_features=self.node_raw_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tedge_features=self.edge_raw_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmemory=self.memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tneighbor_finder=self.neighbor_finder,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttime_encoder=self.time_encoder,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_layers=self.n_layers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_node_features=self.n_node_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_edge_features=self.n_edge_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_time_features=self.n_node_features,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tembedding_dimension=self.embedding_dimension,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tdevice=self.device,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_heads=n_heads, dropout=dropout,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tuse_memory=use_memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tn_neighbors=self.n_neighbors)\n",
    "\n",
    "\t\t# MLP to compute probability on an edge given two node embeddings\n",
    "\t\tself.affinity_score = MergeLayer(self.n_node_features, self.n_node_features,\n",
    "\t\t\t\t\t\t\t\t\t\tself.n_node_features,\n",
    "\t\t\t\t\t\t\t\t\t\t1)\n",
    "\n",
    "\t\tself.node_classifier = NodeClassifier(self.n_node_features, hidden_dim=decoder_hidden_dim, out_dim=1, dropout=dropout,)\n",
    "\n",
    "\tdef compute_temporal_embeddings(self, source_nodes, destination_nodes, negative_nodes, edge_times,\n",
    "\t\t\t\t\t\t\t\t\tedge_idxs, n_neighbors=20):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute temporal embeddings for sources, destinations, and negatively sampled destinations.\n",
    "\n",
    "\t\tsource_nodes [batch_size]: source ids.\n",
    "\t\t:param destination_nodes [batch_size]: destination ids\n",
    "\t\t:param negative_nodes [batch_size]: ids of negative sampled destination\n",
    "\t\t:param edge_times [batch_size]: timestamp of interaction\n",
    "\t\t:param edge_idxs [batch_size]: index of interaction\n",
    "\t\t:param n_neighbors [scalar]: number of temporal neighbor to consider in each convolutional\n",
    "\t\tlayer\n",
    "\t\t:return: Temporal embeddings for sources, destinations and negatives\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tn_samples = len(source_nodes)\n",
    "\t\tnodes = np.concatenate([source_nodes, destination_nodes, negative_nodes]) if negative_nodes else np.concatenate([source_nodes, destination_nodes])\n",
    "\t\tpositives = np.concatenate([source_nodes, destination_nodes])\n",
    "\t\ttimestamps = np.concatenate([edge_times, edge_times, edge_times]) if negative_nodes else np.concatenate([edge_times, edge_times])\n",
    "\n",
    "\t\tmemory = None\n",
    "\t\ttime_diffs = None\n",
    "\t\tif self.use_memory:\n",
    "\t\t\tif self.memory_update_at_start:\n",
    "\t\t\t\t# Update memory for all nodes with messages stored in previous batches\n",
    "\t\t\t\tmemory, last_update = self.get_updated_memory(list(range(self.n_nodes)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.memory.messages)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmemory = self.memory.get_memory(list(range(self.n_nodes)))\n",
    "\t\t\t\tlast_update = self.memory.last_update\n",
    "\n",
    "\t\t### Compute differences between the time the memory of a node was last updated,\n",
    "\t\t### and the time for which we want to compute the embedding of a node\n",
    "\t\tsource_time_diffs = torch.LongTensor(edge_times).to(self.device) - last_update[\n",
    "\t\t\tsource_nodes].long()\n",
    "\t\tsource_time_diffs = (source_time_diffs - self.mean_time_shift_src) / self.std_time_shift_src\n",
    "\n",
    "\t\tdestination_time_diffs = torch.LongTensor(edge_times).to(self.device) - last_update[\n",
    "\t\t\tdestination_nodes].long()\n",
    "\t\tdestination_time_diffs = (destination_time_diffs - self.mean_time_shift_dst) / self.std_time_shift_dst\n",
    "\n",
    "\t\tif negative_nodes:\n",
    "\t\t\tnegative_time_diffs = torch.LongTensor(edge_times).to(self.device) - last_update[\n",
    "\t\t\t\tnegative_nodes].long()\n",
    "\t\t\tnegative_time_diffs = (negative_time_diffs - self.mean_time_shift_dst) / self.std_time_shift_dst\n",
    "\n",
    "\t\t\ttime_diffs = torch.cat([source_time_diffs, destination_time_diffs, negative_time_diffs],\n",
    "\t\t\t\t\t\t\t\t\tdim=0)\n",
    "\t\telse:\n",
    "\t\t\ttime_diffs = torch.cat([source_time_diffs, destination_time_diffs], dim=0)\n",
    "\n",
    "\t\t# Compute the embeddings using the embedding module\n",
    "\t\tnode_embedding = self.embedding_module.compute_embedding(memory=memory,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_nodes=nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimestamps=timestamps,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_layers=self.n_layers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_neighbors=n_neighbors,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttime_diffs=time_diffs)\n",
    "\n",
    "\t\tsource_node_embedding = node_embedding[:n_samples]\n",
    "\t\tdestination_node_embedding = node_embedding[n_samples: 2 * n_samples]\n",
    "\t\tnegative_node_embedding = node_embedding[2 * n_samples:]\n",
    "\n",
    "\t\tif self.use_memory:\n",
    "\t\t\tif self.memory_update_at_start:\n",
    "\t\t\t\t# Persist the updates to the memory only for sources and destinations (since now we have\n",
    "\t\t\t\t# new messages for them)\n",
    "\t\t\t\tself.update_memory(positives, self.memory.messages)\n",
    "\n",
    "\t\t\t\tassert torch.allclose(memory[positives], self.memory.get_memory(positives), atol=1e-5), \\\n",
    "\t\t\t\t\"Something wrong in how the memory was updated\"\n",
    "\n",
    "\t\t\t\t# Remove messages for the positives since we have already updated the memory using them\n",
    "\t\t\t\tself.memory.clear_messages(positives)\n",
    "\n",
    "\t\t\tunique_sources, source_id_to_messages = self.get_raw_messages(source_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_node_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdestination_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdestination_node_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tedge_times, edge_idxs)\n",
    "\t\t\tunique_destinations, destination_id_to_messages = self.get_raw_messages(destination_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdestination_node_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_node_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tedge_times, edge_idxs)\n",
    "\t\tif self.memory_update_at_start:\n",
    "\t\t\tself.memory.store_raw_messages(unique_sources, source_id_to_messages)\n",
    "\t\t\tself.memory.store_raw_messages(unique_destinations, destination_id_to_messages)\n",
    "\t\telse:\n",
    "\t\t\tself.update_memory(unique_sources, source_id_to_messages)\n",
    "\t\t\tself.update_memory(unique_destinations, destination_id_to_messages)\n",
    "\n",
    "\t\treturn source_node_embedding, destination_node_embedding, negative_node_embedding\n",
    "\n",
    "\tdef compute_edge_probabilities(self, source_nodes, destination_nodes, negative_nodes, edge_times,\n",
    "\t\t\t\t\t\t\t\t\tedge_idxs, n_neighbors=20):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute probabilities for edges between sources and destination and between sources and\n",
    "\t\tnegatives by first computing temporal embeddings using the TGN encoder and then feeding them\n",
    "\t\tinto the MLP decoder.\n",
    "\t\t:param destination_nodes [batch_size]: destination ids\n",
    "\t\t:param negative_nodes [batch_size]: ids of negative sampled destination\n",
    "\t\t:param edge_times [batch_size]: timestamp of interaction\n",
    "\t\t:param edge_idxs [batch_size]: index of interaction\n",
    "\t\t:param n_neighbors [scalar]: number of temporal neighbor to consider in each convolutional\n",
    "\t\tlayer\n",
    "\t\t:return: Probabilities for both the positive and negative edges\n",
    "\t\t\"\"\"\n",
    "\t\tn_samples = len(source_nodes)\n",
    "\t\tsource_node_embedding, destination_node_embedding, negative_node_embedding = self.compute_temporal_embeddings(\n",
    "\t\tsource_nodes, destination_nodes, negative_nodes, edge_times, edge_idxs, n_neighbors)\n",
    "\n",
    "\t\tscore = self.affinity_score(torch.cat([source_node_embedding, source_node_embedding], dim=0),\n",
    "\t\t\t\t\t\t\t\t\ttorch.cat([destination_node_embedding,\n",
    "\t\t\t\t\t\t\t\t\t\t\tnegative_node_embedding])).squeeze(dim=0)\n",
    "\t\tpos_score = score[:n_samples]\n",
    "\t\tneg_score = score[n_samples:]\n",
    "\n",
    "\t\treturn pos_score.sigmoid(), neg_score.sigmoid()\n",
    "\n",
    "\tdef compute_node_predictions(self, source_nodes, destination_nodes, edge_times, edge_idxs, n_neighbors=20):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute binary label predictions for nodes involved in each edge.\n",
    "\t\t:param source_nodes [batch_size]: source ids\n",
    "\t\t:param destination_nodes [batch_size]: destination ids\n",
    "\t\t:param edge_times [batch_size]: timestamp of interaction\n",
    "\t\t:param edge_idxs [batch_size]: index of interaction\n",
    "\t\t:param n_neighbors [scalar]: number of temporal neighbors to consider in each convolutional layer\n",
    "\t\t:return: Predicted binary labels for each source and destination node\n",
    "\t\t\"\"\"\n",
    "\t\t# Compute temporal embeddings for source and destination nodes\n",
    "\t\tsource_node_embedding, destination_node_embedding, _ = self.compute_temporal_embeddings(\n",
    "\t\t\tsource_nodes, destination_nodes, negative_nodes=[], edge_times=edge_times, edge_idxs=edge_idxs, n_neighbors=n_neighbors)\n",
    "\n",
    "\t\t# Predict labels for each source and destination node\n",
    "\t\tsource_node_preds = self.node_classifier(source_node_embedding).squeeze(dim=1)\n",
    "\t\tdestination_node_preds = self.node_classifier(destination_node_embedding).squeeze(dim=1)\n",
    "\n",
    "\t\treturn source_node_preds.sigmoid(), destination_node_preds.sigmoid()\n",
    "\n",
    "\tdef update_memory(self, nodes, messages):\n",
    "\t\t# Aggregate messages for the same nodes\n",
    "\t\tunique_nodes, unique_messages, unique_timestamps = \\\n",
    "\t\tself.message_aggregator.aggregate(\n",
    "\t\t\tnodes,\n",
    "\t\t\tmessages)\n",
    "\n",
    "\t\tif len(unique_nodes) > 0:\n",
    "\t\t\tunique_messages = self.message_function.compute_message(unique_messages)\n",
    "\n",
    "\t\t# Update the memory with the aggregated messages\n",
    "\t\tself.memory_updater.update_memory(unique_nodes, unique_messages,\n",
    "\t\t\t\t\t\t\t\t\t\ttimestamps=unique_timestamps)\n",
    "\n",
    "\tdef get_updated_memory(self, nodes, messages):\n",
    "\t\t# Aggregate messages for the same nodes\n",
    "\t\tunique_nodes, unique_messages, unique_timestamps = \\\n",
    "\t\tself.message_aggregator.aggregate(\n",
    "\t\t\tnodes,\n",
    "\t\t\tmessages)\n",
    "\n",
    "\t\tif len(unique_nodes) > 0:\n",
    "\t\t\tunique_messages = self.message_function.compute_message(unique_messages)\n",
    "\n",
    "\n",
    "\t\tupdated_memory, updated_last_update = self.memory_updater.get_updated_memory(unique_nodes,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tunique_messages,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimestamps=unique_timestamps)\n",
    "\n",
    "\t\treturn updated_memory, updated_last_update\n",
    "\n",
    "\tdef get_raw_messages(self, source_nodes, source_node_embedding, destination_nodes,\n",
    "\t\t\t\t\t\tdestination_node_embedding, edge_times, edge_idxs):\n",
    "\t\tedge_times = torch.from_numpy(edge_times).float().to(self.device)\n",
    "\t\tedge_features = self.edge_raw_features[edge_idxs]\n",
    "\n",
    "\t\tsource_memory = self.memory.get_memory(source_nodes) if not \\\n",
    "\t\tself.use_source_embedding_in_message else source_node_embedding\n",
    "\t\tdestination_memory = self.memory.get_memory(destination_nodes) if \\\n",
    "\t\tnot self.use_destination_embedding_in_message else destination_node_embedding\n",
    "\n",
    "\t\tsource_time_delta = edge_times - self.memory.last_update[source_nodes]\n",
    "\t\tsource_time_delta_encoding = self.time_encoder(source_time_delta.unsqueeze(dim=1)).view(len(\n",
    "\t\tsource_nodes), -1)\n",
    "\n",
    "\t\tsource_message = torch.cat([source_memory, destination_memory, edge_features,\n",
    "\t\t\t\t\t\t\t\t\tsource_time_delta_encoding],\n",
    "\t\t\t\t\t\t\t\tdim=1)\n",
    "\t\tmessages = defaultdict(list)\n",
    "\t\tunique_sources = np.unique(source_nodes)\n",
    "\n",
    "\t\tfor i in range(len(source_nodes)):\n",
    "\t\t\tmessages[source_nodes[i]].append((source_message[i], edge_times[i]))\n",
    "\n",
    "\t\treturn unique_sources, messages\n",
    "\n",
    "\tdef set_neighbor_finder(self, neighbor_finder):\n",
    "\t\tself.neighbor_finder = neighbor_finder\n",
    "\t\tself.embedding_module.neighbor_finder = neighbor_finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h5Y4fX51l8-"
   },
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5H5aU2kX1l8-"
   },
   "outputs": [],
   "source": [
    "# Initialize training neighbor finder to retrieve temporal graph\n",
    "train_ngh_finder = get_neighbor_finder(train_data, uniform=False)\n",
    "valid_ngh_finder = get_neighbor_finder(val_data, uniform=False)\n",
    "test_ngh_finder = get_neighbor_finder(test_data, uniform=False)\n",
    "\n",
    "# Set device\n",
    "device_string = 'cuda:{}'.format(GPU) if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_string)\n",
    "\n",
    "# Compute time statistics\n",
    "mean_time_shift_src, std_time_shift_src, mean_time_shift_dst, std_time_shift_dst = \\\n",
    "  compute_time_statistics(full_data.sources, full_data.destinations, full_data.timestamps)\n",
    "\n",
    "def get_batch_indices(dataset_size: int, batch_size: int):\n",
    "    \"\"\"\n",
    "    Generate batch indices for iterating over a dataset.\n",
    "\n",
    "    :param dataset_size: Total number of samples in the dataset\n",
    "    :param batch_size: Number of samples per batch\n",
    "    :return: List of tuples, where each tuple contains the start and end index for each batch\n",
    "    \"\"\"\n",
    "    batch_indices = []\n",
    "    for start_idx in range(0, dataset_size, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, dataset_size)\n",
    "        batch_indices.append((start_idx, end_idx))\n",
    "    return batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHTlIOGN1l8-"
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AXjpew91l8_"
   },
   "outputs": [],
   "source": [
    "res = dict()\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 5  # Number of epochs to wait before stopping if no improvement\n",
    "best_auc = -float('inf')  # Initialize best AUC to negative infinity\n",
    "no_improvement_counter = 0  # Counter for epochs without improvement\n",
    "\n",
    "# Calculate class proportions for the random baseline\n",
    "source_class_proportion = np.mean(train_data.source_labels)  # P(1) for sources\n",
    "destination_class_proportion = np.mean(train_data.dest_labels)  # P(1) for destinations\n",
    "logger.info(f\"Source Class Proportion: {source_class_proportion}\")\n",
    "logger.info(f\"Destination Class Proportion: {destination_class_proportion}\")\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "tgn = TGN(\n",
    "    neighbor_finder=train_ngh_finder,\n",
    "    node_features=node_features,\n",
    "\tedge_features=edge_features.reshape(-1, 1),\n",
    "    device=device,\n",
    "\tn_layers=NUM_LAYER,\n",
    "\tn_heads=NUM_HEADS,\n",
    "    dropout=DROP_OUT,\n",
    "    use_memory=USE_MEMORY,\n",
    "\tmessage_dimension=MESSAGE_DIM,\n",
    "    memory_dimension=MEMORY_DIM,\n",
    "\tmemory_update_at_start=not memory_update_at_end,\n",
    "\tembedding_module_type=embedding_module,\n",
    "\tmessage_function=message_function,\n",
    "\taggregator_type=aggregator,\n",
    "\tmemory_updater_type=memory_updater,\n",
    "\tn_neighbors=NUM_NEIGHBORS,\n",
    "\tmean_time_shift_src=mean_time_shift_src,\n",
    "    std_time_shift_src=std_time_shift_src,\n",
    "\tmean_time_shift_dst=mean_time_shift_dst,\n",
    "    std_time_shift_dst=std_time_shift_dst,\n",
    "\tuse_destination_embedding_in_message=use_destination_embedding_in_message,\n",
    "\tuse_source_embedding_in_message=use_source_embedding_in_message,\n",
    "    decoder_hidden_dim=DECODER_HIDDEN_DIM,\n",
    ")\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(tgn.parameters(), lr=LEARNING_RATE)\n",
    "tgn = tgn.to(device)\n",
    "\n",
    "num_instance = len(train_data.sources)\n",
    "num_batch = math.ceil(num_instance / BATCH_SIZE)\n",
    "\n",
    "logger.info('num of training instances: {}'.format(num_instance))\n",
    "logger.info('num of batches per epoch: {}'.format(num_batch))\n",
    "idx_list = np.arange(num_instance)\n",
    "\n",
    "new_nodes_val_aps = []\n",
    "val_aps = []\n",
    "epoch_times = []\n",
    "total_epoch_times = []\n",
    "train_losses = []\n",
    "\n",
    "dataset_size = train_data.sources.shape[0]\n",
    "batch_indices = get_batch_indices(dataset_size, BATCH_SIZE)\n",
    "\n",
    "# Define training loop\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    epoch_loss = 0\n",
    "    start_epoch = time.time()\n",
    "\n",
    "    # Reinitialize memory of the model at the start of each epoch if needed\n",
    "    if USE_MEMORY:\n",
    "        tgn.memory.__init_memory__()\n",
    "\n",
    "    # Set neighbor finder to use training data\n",
    "    tgn.set_neighbor_finder(train_ngh_finder)\n",
    "\n",
    "    logger.info(f'Starting epoch {epoch+1}/{NUM_EPOCH}')\n",
    "    for k in tqdm(range(0, num_batch, BACKPROP_EVERY)):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for j in range(BACKPROP_EVERY):\n",
    "            batch_idx = k + j\n",
    "            if batch_idx >= num_batch:\n",
    "                continue\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(num_instance, start_idx + BATCH_SIZE)\n",
    "            # Extract the batch data\n",
    "            sources_batch = train_data.sources[start_idx:end_idx]\n",
    "            destinations_batch = train_data.destinations[start_idx:end_idx]\n",
    "            edge_idxs_batch = train_data.edge_idxs[start_idx:end_idx]\n",
    "            timestamps_batch = train_data.timestamps[start_idx:end_idx]\n",
    "            sources_labels_batch = torch.from_numpy(train_data.source_labels[start_idx:end_idx]).float()\n",
    "            destinations_labels_batch = torch.from_numpy(train_data.dest_labels[start_idx:end_idx]).float()\n",
    "\n",
    "\n",
    "            sources_labels_batch = sources_labels_batch.to(device)\n",
    "            destinations_labels_batch = destinations_labels_batch.to(device)\n",
    "\n",
    "            # Set model to training mode\n",
    "            tgn.train()\n",
    "\n",
    "            # Forward pass for node predictions\n",
    "            source_preds, destination_preds = tgn.compute_node_predictions(sources_batch, destinations_batch, timestamps_batch, edge_idxs_batch, NUM_NEIGHBORS)\n",
    "\n",
    "            # Compute the loss for sources and destinations\n",
    "            source_loss = criterion(source_preds.squeeze(), sources_labels_batch)\n",
    "            destination_loss = criterion(destination_preds.squeeze(), destinations_labels_batch)\n",
    "            loss += source_loss + destination_loss\n",
    "        loss /= BACKPROP_EVERY\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if USE_MEMORY:\n",
    "            tgn.memory.detach_memory()\n",
    "\n",
    "    # Average epoch loss\n",
    "    avg_epoch_loss = epoch_loss / len(batch_indices)\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "\n",
    "    # Epoch time and logging\n",
    "    epoch_time = time.time() - start_epoch\n",
    "    epoch_times.append(epoch_time)\n",
    "    logger.info(f\"Epoch {epoch+1}/{NUM_EPOCH} completed in {epoch_time:.2f}s with loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    if (epoch + 1) % validate_every == 0:\n",
    "        tgn.set_neighbor_finder(valid_ngh_finder)\n",
    "        if USE_MEMORY:\n",
    "          # Backup memory at the end of training, so later we can restore it and use it for the validation on unseen nodes\n",
    "          train_memory_backup = tgn.memory.backup_memory()\n",
    "          tgn.memory.restore_memory(train_memory_backup)\n",
    "        val_loss = 0.0\n",
    "        tgn.eval()\n",
    "\n",
    "        sources_val_true_classes = []\n",
    "        sources_val_pred_classes = []\n",
    "        sources_val_pred_probs = []\n",
    "\n",
    "        destinations_val_true_classes = []\n",
    "        destinations_val_pred_classes = []\n",
    "        destinations_val_pred_probs = []\n",
    "\n",
    "        # Initialize lists for random classifier predictions\n",
    "        sources_random_pred_probs = []\n",
    "        destinations_random_pred_probs = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculations\n",
    "            for batch_idx in range(0, len(val_data.sources), BATCH_SIZE):\n",
    "                start_idx = batch_idx\n",
    "                end_idx = min(len(val_data.sources), start_idx + BATCH_SIZE)\n",
    "                sources_batch_val = val_data.sources[start_idx:end_idx]\n",
    "                destinations_batch_val = val_data.destinations[start_idx:end_idx]\n",
    "                edge_idxs_batch_val = val_data.edge_idxs[start_idx:end_idx]\n",
    "                timestamps_batch_val = val_data.timestamps[start_idx:end_idx]\n",
    "                sources_labels_batch_val = torch.from_numpy(val_data.source_labels[start_idx:end_idx]).float().to(device)\n",
    "                destinations_labels_batch_val = torch.from_numpy(val_data.dest_labels[start_idx:end_idx]).float().to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                source_preds_val, destination_preds_val = tgn.compute_node_predictions(\n",
    "                    sources_batch_val, destinations_batch_val, timestamps_batch_val, edge_idxs_batch_val, NUM_NEIGHBORS\n",
    "                )\n",
    "\n",
    "                # Compute validation loss\n",
    "                source_loss = criterion(source_preds_val.squeeze(), sources_labels_batch_val)\n",
    "                destination_loss = criterion(destination_preds_val.squeeze(), destinations_labels_batch_val)\n",
    "                batch_val_loss = source_loss + destination_loss\n",
    "                val_loss += batch_val_loss.item()\n",
    "\n",
    "                # Collect predictions and labels for source nodes\n",
    "                sources_val_true_classes.extend(sources_labels_batch_val.cpu().numpy().tolist())\n",
    "                # Collect predicted probabilities\n",
    "                sources_val_pred_probs.extend(source_preds_val.squeeze().tolist())\n",
    "                # Generate class predictions based on the threshold\n",
    "                sources_val_pred_classes_batch = (source_preds_val > threshold).float().cpu().numpy()\n",
    "                sources_val_pred_classes.extend(sources_val_pred_classes_batch.tolist())\n",
    "\n",
    "                # Collect predictions and labels for destination nodes\n",
    "                destinations_val_true_classes.extend(destinations_labels_batch_val.cpu().numpy().tolist())\n",
    "                # Collect predicted probabilities\n",
    "                destinations_val_pred_probs.extend(destination_preds_val.squeeze().tolist())\n",
    "                # Generate class predictions based on the threshold\n",
    "                destinations_val_pred_classes_batch = (destination_preds_val > threshold).float().cpu().numpy()\n",
    "                destinations_val_pred_classes.extend(destinations_val_pred_classes_batch.tolist())\n",
    "\n",
    "                # Random classifier predictions based on class proportions\n",
    "                sources_random_pred_probs.extend(\n",
    "                    np.random.choice([0, 1], size=len(sources_labels_batch_val), p=[1 - source_class_proportion, source_class_proportion], replace=True)\n",
    "                )\n",
    "                destinations_random_pred_probs.extend(\n",
    "                    np.random.choice([0, 1], size=len(destinations_labels_batch_val), p=[1 - destination_class_proportion, destination_class_proportion], replace=True)\n",
    "                )\n",
    "\n",
    "        # Compute final validation metrics for the epoch\n",
    "        avg_val_loss = val_loss / len(val_data.sources)\n",
    "\n",
    "        # Validation AUC\n",
    "        val_auc_sources = roc_auc_score(sources_val_true_classes, sources_val_pred_probs)\n",
    "        val_auc_destinations = roc_auc_score(destinations_val_true_classes, destinations_val_pred_probs)\n",
    "        val_auc = np.mean([val_auc_sources, val_auc_destinations])\n",
    "        logger.info(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Calculate AUC for random classifier predictions\n",
    "        random_auc_sources = roc_auc_score(sources_val_true_classes, sources_random_pred_probs)\n",
    "        random_auc_destinations = roc_auc_score(destinations_val_true_classes, destinations_random_pred_probs)\n",
    "        random_auc = np.mean([random_auc_sources, random_auc_destinations])\n",
    "        logger.info(f\"Random Classifier AUC - Sources: {random_auc_sources:.4f}, Destinations: {random_auc_destinations:.4f}, Average: {random_auc:.4f}\")\n",
    "\n",
    "\n",
    "        # Validation accuracy\n",
    "        val_acc_source = accuracy_score(sources_val_true_classes, sources_val_pred_classes)\n",
    "        val_acc_destinations = accuracy_score(destinations_val_true_classes, destinations_val_pred_classes)\n",
    "        val_acc = np.mean([val_acc_source, val_acc_destinations])\n",
    "        logger.info(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "        random_acc_sources = accuracy_score(sources_val_true_classes, sources_random_pred_probs)\n",
    "        random_acc_destinations = accuracy_score(destinations_val_true_classes, destinations_random_pred_probs)\n",
    "        random_acc = np.mean([random_acc_sources, random_acc_destinations])\n",
    "        logger.info(f\"Random Classifier Accuracy - Sources: {random_acc_sources:.4f}, Destinations: {random_acc_destinations:.4f}, Average: {random_acc:.4f}\")\n",
    "\n",
    "        # Validation precision\n",
    "        val_prec_source = precision_score(sources_val_true_classes, sources_val_pred_classes, average=\"weighted\")\n",
    "        val_prec_destinations = precision_score(destinations_val_true_classes, destinations_val_pred_classes, average=\"weighted\")\n",
    "        val_prec = np.mean([val_prec_source, val_prec_destinations])\n",
    "        logger.info(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}, Validation Precision: {val_prec:.4f}\")\n",
    "\n",
    "        # Validation recall\n",
    "        val_recall_source = recall_score(sources_val_true_classes, sources_val_pred_classes, average=\"weighted\")\n",
    "        val_recall_destinations = recall_score(destinations_val_true_classes, destinations_val_pred_classes, average=\"weighted\")\n",
    "        val_recall = np.mean([val_recall_source, val_recall_destinations])\n",
    "        logger.info(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}, Validation Recall: {val_recall:.4f}\")\n",
    "\n",
    "        # Validation f1-score\n",
    "        val_f1_source = f1_score(sources_val_true_classes, sources_val_pred_classes, average=\"weighted\")\n",
    "        val_f1_destinations = f1_score(destinations_val_true_classes, destinations_val_pred_classes, average=\"weighted\")\n",
    "        val_f1 = np.mean([val_f1_source, val_f1_destinations])\n",
    "        logger.info(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}, Validation F1-score: {val_f1:.4f}\")\n",
    "        random_f1_sources = f1_score(sources_val_true_classes, sources_random_pred_probs)\n",
    "        random_f1_destinations = f1_score(destinations_val_true_classes, destinations_random_pred_probs)\n",
    "        random_f1 = np.mean([random_f1_sources, random_f1_destinations])\n",
    "        logger.info(f\"Random Classifier F1-score - Sources: {random_f1_sources:.4f}, Destinations: {random_f1_destinations:.4f}, Average: {random_f1:.4f}\")\n",
    "\n",
    "        # Generate classification report as a dictionary\n",
    "        val_y_true = sources_val_true_classes + destinations_val_true_classes\n",
    "        val_y_pred = sources_val_pred_classes + destinations_val_pred_classes\n",
    "        val_report_dict = classification_report(val_y_true, val_y_pred, output_dict=True)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        val_report_df = pd.DataFrame(val_report_dict).transpose()\n",
    "\n",
    "        # Display the DataFrame\n",
    "        logger.info(f\"Classification report:\\n{val_report_df}\")\n",
    "        logger.info(f\"Classification report (source):\\n{pd.DataFrame(classification_report(sources_val_true_classes, sources_val_pred_classes, output_dict=True)).transpose()}\")\n",
    "        logger.info(f\"Classification report (destination):\\n{pd.DataFrame(classification_report(destinations_val_true_classes, destinations_val_pred_classes, output_dict=True)).transpose()}\")\n",
    "\n",
    "        val_report_df.to_excel(PATH_OUTPUT / f\"val_cr_epoch_{epoch+1}.xlsx\")\n",
    "\n",
    "        # Save results\n",
    "        epoch_res = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_epoch_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "\n",
    "            'val_auc_sources': val_auc_sources,\n",
    "            'val_auc_destinations': val_auc_destinations,\n",
    "            'val_auc': val_auc,\n",
    "\n",
    "            'val_acc_source': val_acc_source,\n",
    "            'val_acc_destinations': val_acc_destinations,\n",
    "            'val_acc': val_acc,\n",
    "\n",
    "            'val_prec_source': val_prec_source,\n",
    "            'val_prec_destinations': val_prec_destinations,\n",
    "            'val_prec': val_prec,\n",
    "\n",
    "            'val_recall_source': val_recall_source,\n",
    "            'val_recall_destinations': val_recall_destinations,\n",
    "            'val_recall': val_recall,\n",
    "\n",
    "            'val_f1_source': val_f1_source,\n",
    "            'val_f1_destinations': val_f1_destinations,\n",
    "            'val_f1': val_f1,\n",
    "        }\n",
    "        res[epoch + 1] = epoch_res\n",
    "        # Early Stopping Check\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            logger.info(f\"Found best validation metric at epoch {epoch+1}: {best_auc}\")\n",
    "            no_improvement_counter = 0  # Reset counter when improvement occurs\n",
    "            # Save best results\n",
    "            best_epoch_name = f\"best_{epoch+1}\"\n",
    "            best_epoch_path = PATH_OUTPUT / best_epoch_name\n",
    "            best_epoch_path.mkdir(exist_ok=True, parents=True)\n",
    "            with open(best_epoch_path / \"metrics.json\", \"w\") as fb:\n",
    "                json.dump(res, fb)\n",
    "            with open(best_epoch_path / \"params.json\", \"w\") as fb:\n",
    "                json.dump(parameters, fb)\n",
    "            # Store backup memory\n",
    "            if USE_MEMORY:\n",
    "                val_memory_backup = tgn.memory.backup_memory()\n",
    "                with open(best_epoch_path / \"val_memory_backup.pickle\", \"wb\") as fb:\n",
    "                    pickle.dump(val_memory_backup, fb)\n",
    "                with open(best_epoch_path / \"train_memory_backup.pickle\", \"wb\") as fb:\n",
    "                    pickle.dump(train_memory_backup, fb)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': tgn.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss_history': loss,\n",
    "                }, best_epoch_path / f\"model_state_{best_epoch_name}.pth\")\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            if no_improvement_counter >= patience:\n",
    "                logger.info(f\"Early stopping at epoch {epoch+1} due to no improvement in validation metric.\")\n",
    "                break  # Stop training\n",
    "parameters = dict(train_size=TRAIN_SIZE,\n",
    "                  test_size=TEST_SIZE,\n",
    "                  gpu=GPU,\n",
    "                  n_layers=NUM_LAYER,\n",
    "                  n_heads=NUM_HEADS,\n",
    "                  dropout=DROP_OUT,\n",
    "                  use_memory=USE_MEMORY,\n",
    "                  message_dim=MESSAGE_DIM,\n",
    "                  memory_dimension=MEMORY_DIM,\n",
    "                  decoder_hidden_dim=DECODER_HIDDEN_DIM,\n",
    "                  memory_update_at_end=memory_update_at_end,\n",
    "                  embedding_module_type=embedding_module,\n",
    "                  message_function=message_function,\n",
    "                  aggregator_type=aggregator,\n",
    "                  memory_updater_type=memory_updater,\n",
    "                  n_neighbors=NUM_NEIGHBORS,\n",
    "                  use_destination_embedding_in_message=use_destination_embedding_in_message,\n",
    "                  use_source_embedding_in_message=use_source_embedding_in_message,\n",
    "                  learning_rate=LEARNING_RATE,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  backprop_every=BACKPROP_EVERY,\n",
    "                  num_epochs=NUM_EPOCH,\n",
    "                  validate_every=validate_every,\n",
    "                  limit=LIMIT,\n",
    "                  threshold=threshold,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLUSJmvZmxit"
   },
   "outputs": [],
   "source": [
    "len(val_y_true), len(val_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmy7DczPm7EY"
   },
   "outputs": [],
   "source": [
    "pd.Series(val_y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yeXfHsvnFr5"
   },
   "outputs": [],
   "source": [
    "pd.Series(val_y_true).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJgyovmomh_H"
   },
   "source": [
    "## Metrics on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSUdr0joZViQ"
   },
   "outputs": [],
   "source": [
    "print(f\"{best_epoch_path=}\")\n",
    "print(f\"{best_epoch_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxISVA9pZaQt"
   },
   "outputs": [],
   "source": [
    "with open(best_epoch_path / \"params.json\", \"r\") as fb:\n",
    "  parameters = json.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CV-HThKjcR9u"
   },
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpUW5Gt_XhlM"
   },
   "outputs": [],
   "source": [
    "trained_model_conf = torch.load(best_epoch_path / f\"model_state_{best_epoch_name}.pth\")\n",
    "trained_model = TGN(\n",
    "    neighbor_finder=test_ngh_finder,\n",
    "    node_features=node_features,\n",
    "\tedge_features=edge_features.reshape(-1, 1),\n",
    "\tdevice=device,\n",
    "\tn_layers=parameters[\"n_layers\"],\n",
    "\tn_heads=parameters[\"n_heads\"],\n",
    "\tdropout=parameters[\"dropout\"],\n",
    "\tuse_memory=parameters[\"use_memory\"],\n",
    "\tmessage_dimension=parameters[\"message_dim\"],\n",
    "\tmemory_dimension=parameters[\"memory_dimension\"],\n",
    "\tmemory_update_at_start=not parameters[\"memory_update_at_end\"],\n",
    "\tembedding_module_type=parameters[\"embedding_module_type\"],\n",
    "\tmessage_function=parameters[\"message_function\"],\n",
    "\taggregator_type=parameters[\"aggregator_type\"],\n",
    "\tmemory_updater_type=parameters[\"memory_updater_type\"],\n",
    "\tn_neighbors=parameters[\"n_neighbors\"],\n",
    "\tmean_time_shift_src=mean_time_shift_src,\n",
    "\tstd_time_shift_src=std_time_shift_src,\n",
    "\tmean_time_shift_dst=mean_time_shift_dst,\n",
    "\tstd_time_shift_dst=std_time_shift_dst,\n",
    "\tuse_destination_embedding_in_message=parameters[\"use_destination_embedding_in_message\"],\n",
    "\tuse_source_embedding_in_message=parameters[\"use_source_embedding_in_message\"],\n",
    "\tdecoder_hidden_dim=parameters[\"decoder_hidden_dim\"],\n",
    ")\n",
    "trained_model.load_state_dict(trained_model_conf[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWV-ffHz00KX"
   },
   "outputs": [],
   "source": [
    "with open(best_epoch_path / \"val_memory_backup.pickle\", \"rb\") as fb:\n",
    "    val_memory_backup = pickle.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Mon3uExoibX"
   },
   "outputs": [],
   "source": [
    "with open(best_epoch_path / \"train_memory_backup.pickle\", \"rb\") as fb:\n",
    "    train_memory_backup = pickle.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbEVTDu0mhDg"
   },
   "outputs": [],
   "source": [
    "# Restore memory after validation so it can be used for testing (since test edges are strictly later in time than validation edges)\n",
    "if parameters[\"use_memory\"]:\n",
    "  trained_model.memory.restore_memory(val_memory_backup)\n",
    "\n",
    "trained_model.set_neighbor_finder(test_ngh_finder)\n",
    "trained_model.to(device)\n",
    "trained_model.eval()\n",
    "\n",
    "sources_test_true_classes = []\n",
    "sources_test_pred_classes = []\n",
    "sources_test_pred_probs = []\n",
    "\n",
    "destinations_test_true_classes = []\n",
    "destinations_test_pred_classes = []\n",
    "destinations_test_pred_probs = []\n",
    "\n",
    "sources_test_random_pred_probs = []\n",
    "sources_test_random_pred_classes = []\n",
    "destinations_test_random_pred_probs = []\n",
    "destinations_test_random_pred_classes = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    for batch_idx in range(0, len(test_data.sources), BATCH_SIZE):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(len(test_data.sources), start_idx + BATCH_SIZE)\n",
    "        sources_batch_test = test_data.sources[start_idx:end_idx]\n",
    "        destinations_batch_test = test_data.destinations[start_idx:end_idx]\n",
    "        edge_idxs_batch_test = test_data.edge_idxs[start_idx:end_idx]\n",
    "        timestamps_batch_test = test_data.timestamps[start_idx:end_idx]\n",
    "        sources_labels_batch_test = torch.from_numpy(test_data.source_labels[start_idx:end_idx]).float().to(device)\n",
    "        destinations_labels_batch_test = torch.from_numpy(test_data.dest_labels[start_idx:end_idx]).float().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        source_preds_test, destination_preds_test = trained_model.compute_node_predictions(\n",
    "            sources_batch_test, destinations_batch_test, timestamps_batch_test, edge_idxs_batch_test, NUM_NEIGHBORS\n",
    "        )\n",
    "\n",
    "        # Random classifier predictions based on class proportions\n",
    "        sources_test_random_pred_probs.extend(\n",
    "            np.random.choice([0, 1], size=len(sources_labels_batch_test), p=[1 - source_class_proportion, source_class_proportion], replace=True)\n",
    "        )\n",
    "        destinations_test_random_pred_probs.extend(\n",
    "            np.random.choice([0, 1], size=len(destinations_labels_batch_test), p=[1 - destination_class_proportion, destination_class_proportion], replace=True)\n",
    "        )\n",
    "\n",
    "        # Collect predictions and labels for source nodes\n",
    "        sources_test_true_classes.extend(sources_labels_batch_test.cpu().numpy().tolist())\n",
    "        # Collect predicted probabilities\n",
    "        sources_test_pred_probs.extend(source_preds_test.squeeze().tolist())\n",
    "        # Generate class predictions based on the threshold\n",
    "        sources_test_pred_classes_batch = (source_preds_test > threshold).float().cpu().numpy()\n",
    "        sources_test_pred_classes.extend(sources_test_pred_classes_batch.tolist())\n",
    "\n",
    "        # Collect predictions and labels for destination nodes\n",
    "        destinations_test_true_classes.extend(destinations_labels_batch_test.cpu().numpy().tolist())\n",
    "        # Collect predicted probabilities\n",
    "        destinations_test_pred_probs.extend(destination_preds_test.squeeze().tolist())\n",
    "        # Generate class predictions based on the threshold\n",
    "        destinations_test_pred_classes_batch = (destination_preds_test > threshold).float().cpu().numpy()\n",
    "        destinations_test_pred_classes.extend(destinations_test_pred_classes_batch.tolist())\n",
    "\n",
    "\n",
    "# Test AUC\n",
    "test_auc_sources = roc_auc_score(sources_test_true_classes, sources_test_pred_probs)\n",
    "test_auc_destinations = roc_auc_score(destinations_test_true_classes, destinations_test_pred_probs)\n",
    "test_auc = np.mean([test_auc_sources, test_auc_destinations])\n",
    "logger.info(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Calculate AUC for random classifier predictions\n",
    "test_random_auc_sources = roc_auc_score(sources_test_true_classes, sources_test_random_pred_probs)\n",
    "test_random_auc_destinations = roc_auc_score(destinations_test_true_classes, destinations_test_random_pred_probs)\n",
    "test_random_auc = np.mean([test_random_auc_sources, test_random_auc_destinations])\n",
    "logger.info(f\"Random Classifier AUC - Sources: {test_random_auc_sources:.4f}, Destinations: {test_random_auc_destinations:.4f}, Average: {test_random_auc:.4f}\")\n",
    "\n",
    "# Test random Accuracy\n",
    "test_random_acc_sources = accuracy_score(sources_test_true_classes, sources_test_random_pred_probs)\n",
    "test_random_acc_destinations = accuracy_score(destinations_test_true_classes, destinations_test_random_pred_probs)\n",
    "test_random_acc = np.mean([test_random_acc_sources, test_random_acc_destinations])\n",
    "logger.info(f\"Random Classifier Accuracy - Sources: {test_random_acc_sources:.4f}, Destinations: {test_random_acc_destinations:.4f}, Average: {test_random_acc:.4f}\")\n",
    "\n",
    "# Test precision\n",
    "test_prec_source = precision_score(sources_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_prec_destinations = precision_score(destinations_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_prec = np.mean([test_prec_source, test_prec_destinations])\n",
    "logger.info(f\"Test Precision: {test_prec:.4f}\")\n",
    "\n",
    "# Test recall\n",
    "test_recall_source = recall_score(sources_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_recall_destinations = recall_score(destinations_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_recall = np.mean([test_recall_source, test_recall_destinations])\n",
    "logger.info(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Test f1-score\n",
    "test_f1_source = f1_score(sources_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_f1_destinations = f1_score(destinations_test_true_classes, destinations_test_pred_classes, average=\"weighted\")\n",
    "test_f1 = np.mean([test_f1_source, test_f1_destinations])\n",
    "logger.info(f\"Test F1-score: {test_f1:.4f}\")\n",
    "test_random_f1_sources = f1_score(sources_test_true_classes, sources_test_random_pred_probs)\n",
    "test_random_f1_destinations = f1_score(destinations_test_true_classes, destinations_test_random_pred_probs)\n",
    "test_random_f1 = np.mean([test_random_f1_sources, test_random_f1_destinations])\n",
    "logger.info(f\"Random Classifier F1-score - Sources: {test_random_f1_sources:.4f}, Destinations: {test_random_f1_destinations:.4f}, Average: {test_random_f1:.4f}\")\n",
    "\n",
    "# Generate classification report as a dictionary\n",
    "test_y_true = sources_test_true_classes + destinations_test_true_classes\n",
    "test_y_pred = sources_test_pred_classes + destinations_test_pred_classes\n",
    "test_report_dict = classification_report(test_y_true, test_y_pred, output_dict=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_report_df = pd.DataFrame(test_report_dict).transpose()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(test_report_df)\n",
    "\n",
    "test_report_df.to_excel(PATH_OUTPUT / \"test_cr.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9skoczHhqeQS"
   },
   "outputs": [],
   "source": [
    "pd.Series(test_y_true).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-udYu8a-qXUo"
   },
   "outputs": [],
   "source": [
    "pd.Series(test_y_pred).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKiTH8P6mhOL"
   },
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aKKWPUpR1l87",
    "k-5Ei0cj1l88",
    "Cn6uh0TP1l88",
    "mk5CICQI1l88",
    "e20_Z2yp1l88"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
